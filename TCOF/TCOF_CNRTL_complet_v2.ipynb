{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981e0876",
   "metadata": {},
   "source": [
    "# Traitement du corpus TCOF - CNRTL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f33e2",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "from bs4.element import NavigableString, Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec235b",
   "metadata": {},
   "source": [
    "# **Téléchargement des corpus depuis le site CNRTL**\n",
    "\n",
    "1. Depuis le site du CNRTL, télécharge chaque corpus dans un fichier compressé .zip (avec les fichiers .trs, .xml, .wav), dans le dossier indiqué par la variable filename\n",
    "2. nomme chaque fichier compressé le nom du corpus, récupéré depuis la page html du site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54577545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_name_cnrtl(number):\n",
    "    url = \"https://tcof.atilf.fr/index.php?r=corpus%2Fview&id={}\".format(number)\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    # Find the h1 tag and extract its text\n",
    "    h1_tag = soup.find('h1')\n",
    "    text = h1_tag.get_text()\n",
    "    # Extract the corpus name from the text\n",
    "    corpus_name = text.replace('Corpus ', '')\n",
    "    return corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,800):\n",
    "    try:\n",
    "        url = 'https://tcof.atilf.fr/index.php?r=corpus/download-corpus&id={}'.format(i)\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            filename = 'E:/Corpus/TCOF_CNRTL/{}.zip'.format(corpus_name_cnrtl(i))\n",
    "            with open(filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31d4bf",
   "metadata": {},
   "source": [
    "# **Fichiers dans le dossier**\n",
    "> **Avant de lancer**: dézipper manuellement tous les fichier zip \n",
    "\n",
    "Le script : \n",
    "1. Recense les fichiers existants pour chaque corpus\n",
    "2. Output un dataframe avec pour chaque corpus, les fichiers existants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_cnrtl(path):\n",
    "    list_corpus_path = [add_path2corpus(path, corpus) for corpus in get_all_folder(path)]\n",
    "    mydict = {}\n",
    "    for corpus_path in list_corpus_path:\n",
    "        dict_corpus = get_corpus_files(corpus_path)\n",
    "        mydict[corpus_path]=dict_corpus\n",
    "    df = pd.DataFrame.from_dict(mydict, orient='index').rename_axis('corpus').reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_files(path):\n",
    "    files = {}\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.xml'):\n",
    "            files['xml']=file\n",
    "        if file.endswith('.trs'):\n",
    "            pattern = r'(anonymise_[\\S]*.trs)'\n",
    "            match = re.search(pattern, file)\n",
    "            if match:\n",
    "                files['anonymise_trs']=file\n",
    "            else:\n",
    "                files['trs']=file\n",
    "        if file.endswith('.wav'):\n",
    "            pattern = r'(anonymise_[\\S]*.wav)'\n",
    "            match = re.search(pattern, file)\n",
    "            if match:\n",
    "                files['anonymise_wav']=file\n",
    "            else:\n",
    "                files['wav']=file\n",
    "        else:\n",
    "            continue\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bebc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path2corpus(path,corpus):\n",
    "    new = '{}\\{}'.format(path, corpus)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_folder(path):\n",
    "    directory = os.listdir(path)\n",
    "    folder_list = []\n",
    "    for folder in directory:\n",
    "        if os.path.isdir(os.path.join(path, folder)):\n",
    "            folder_list.append(folder)\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_corpus_names_col(df):\n",
    "    wav = df['xml'].tolist()\n",
    "    corpus_names = []\n",
    "    for file in wav:\n",
    "        try: \n",
    "            pattern = r'^(.*)\\.xml$'\n",
    "            match = re.search(pattern, file)\n",
    "            if match:\n",
    "                corpus = match.group(1)\n",
    "        except:\n",
    "            corpus = 'NAN'\n",
    "        corpus_names.append(corpus)\n",
    "    df['corpus_name'] = corpus_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre le chemin du dossier \n",
    "path_cnrtl = r'E:\\Corpus\\TCOF_CNRTL'\n",
    "#obtenir le dataframe avec le noms des fichiers du dossier dedans\n",
    "df_cnrtl = get_files_cnrtl(path_cnrtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38939531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl = add_corpus_names_col(df_cnrtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste de tous les fichiers pour chaque corpus\n",
    "df_cnrtl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90996490",
   "metadata": {},
   "source": [
    "# **Extraction des métadonnées (fichier .xml)**\n",
    "\n",
    "1. Extrait toutes les métadonnées depuis le fichier .xml\n",
    "2. Détecte si le fichier est encodé en utf8 ou iso, et le décode selon le format.\n",
    "2. Output un dataframe avec pour chaque corpus, les métadonnées associées extraites depuis le fichier .xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b272c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding'] \n",
    "    # Open the file with the detected encoding\n",
    "    with open(file, 'r', encoding=encoding) as f:\n",
    "        soup = BeautifulSoup(f, \"lxml-xml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ce07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml2df(xml_files):\n",
    "    list_df =  []\n",
    "    for xml_file in xml_files:\n",
    "        soup = detect_encoding(xml_file)\n",
    "        dict_file, locuteur = parsexml(soup)\n",
    "        df_corpus = get_df(dict_file)\n",
    "        locuteur_list = list(locuteur.items())\n",
    "        df_corpus['locuteur'] = [locuteur_list] * len(df_corpus)\n",
    "        list_df.append(df_corpus)\n",
    "    df = pd.concat(list_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72414e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(my_dict):\n",
    "    dict2df_corpus = my_dict.copy()\n",
    "    df_corpus = pd.DataFrame([dict2df_corpus])\n",
    "    return df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general(soup, my_dict, general):\n",
    "    for tag_name in general:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_enregistrement(soup, my_dict, enregistrement):\n",
    "    for tag_name in enregistrement:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_referencement(soup, my_dict, referencement):\n",
    "    for tag_name in referencement:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_transcription(soup, my_dict, transcription):\n",
    "    for tag_name in transcription:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_locuteurs(soup, my_dict, locuteur_tag):\n",
    "    # get all locuteurs\n",
    "    locuteurs = soup.find_all('locuteur')\n",
    "\n",
    "    # create a dictionary of locuteurs\n",
    "    for locuteur in locuteurs[1:]:\n",
    "        loc_principal = locuteur.get('locuteurPrincipal')\n",
    "        loc_nb_tour = locuteur.get('nombre_tours')\n",
    "        loc_identifiant = locuteur.get('identifiant')\n",
    "\n",
    "        # create a new dictionary for this locuteur\n",
    "        dict_locuteur = {}\n",
    "        dict_locuteur['nb_tour'] = loc_nb_tour\n",
    "        dict_locuteur['locuteur_principal'] = loc_principal\n",
    "\n",
    "        for tag_name in locuteur_tag:\n",
    "            tag = locuteur.find(tag_name)\n",
    "            if tag is not None:\n",
    "                tag_value = tag.text.strip()\n",
    "                tag_name = tag.name\n",
    "                dict_locuteur[tag_name] = tag_value\n",
    "        # add this locuteur to the dictionary\n",
    "        my_dict[loc_identifiant] = dict_locuteur\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a29218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsexml(soup):\n",
    "    general = [\"nomDossier\", \"responsable_corpus\",\"droit_acces\",\"lien_autre_corpus\",\"mail\",'logiciel_alignement','anonymisation',\"nombre_locuteurs\",\"relation\",\"type_corpus\",\"modalite_recueil\",\"canal\",\"cadre\",\"degre\",'situation_enonciation',\"genre\",\"support_dialogue\",\"document_annexe\",\"resume\",\"commentaire\",\"createur_fiche\",'date_creation_fiche']\n",
    "    enregistrement = [\"nom_fichier\", \"responsable\", \"autorisation\", \"qualite\",\"taille\",\"duree\",\"date\",\"duree_transcription\",\"debut_timecode_transcription\", \"dernier_timecode_transcription\", \"pays\",\"region\",\"ville\",\"arrondissement\", \"description_lieu\",\"format\"]\n",
    "    transcription = [\"nom_fichier\", \"transcripteur\",\"reviseur\",\"format\", \"nombre_mots\", \"convention_transcription\"]\n",
    "    referencement = [\"nom_corpus\", \"responsable\", \"titre\", \"laboratoire\"]\n",
    "    locuteur_tag = ['age','sexe','etude','formation','profession_actuelle','profession_anterieure','role','degre','statut_francais','autre_langue','relation_locuteur','naissance','residence','appartenance','particularite','nombre_mots','temps_parole']\n",
    "    my_dict = {}\n",
    "    my_dict.update(get_general(soup, my_dict, general))\n",
    "    my_dict.update(get_enregistrement(soup, my_dict, enregistrement))\n",
    "    my_dict.update(get_transcription(soup, my_dict,transcription))\n",
    "    my_dict.update(get_referencement(soup, my_dict, referencement))\n",
    "    locuteur = {}\n",
    "    dict_locuteur = get_locuteurs(soup, locuteur, locuteur_tag)\n",
    "    #my_dict.update(get_locuteurs(soup, my_dict, locuteur_tag))\n",
    "    return my_dict, dict_locuteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files_cnrtl = [r'{}\\{}.xml'.format(x, y).replace('\\\\','/') for x,y in list(zip(df_cnrtl['corpus'].tolist(), df_cnrtl['corpus_name'].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl_metadonnees = xml2df(xml_files_cnrtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liste des métadonnées de chaque corpus\n",
    "df_cnrtl_metadonnees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b029e4",
   "metadata": {},
   "source": [
    "# **Analyse des tag.names pour les fichier .trs**\n",
    "\n",
    "1. Récupère tous les noms des balises utilisées dans le fichier trs\n",
    "2. Compare les noms utilisés dans tous les corpus\n",
    "3. Output un dataframe avec pour chaque corpus, le fichier .trs correspondant, tous les tags utilisés, la différence avec les autres corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef065c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tagsname(xml_file):\n",
    "    # Parse the XML file into an ElementTree object\n",
    "    try : \n",
    "        tree = ET.parse(xml_file)\n",
    "    # Get the root element of the tree\n",
    "        root = tree.getroot()\n",
    "    # Initialize an empty set to store the tag names\n",
    "        tag_names = set()\n",
    "    # Iterate over all elements in the tree and add their tag names to the set\n",
    "        for elem in root.iter():\n",
    "            tag_names.add(elem.tag)\n",
    "    # Return the set of tag names\n",
    "    except: \n",
    "        return \"Pas de fichier trouvé à cet emplacement\"\n",
    "    return tag_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_name(path):\n",
    "    filename = re.search(r'[^\\\\\\/]*?(?=\\.\\w+$)', path).group()\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_tags(xml_files):\n",
    "    corpus_name = [get_corpus_name(xml_file) for xml_file in xml_files]\n",
    "    tags_ = [get_all_tagsname(xml_file) for xml_file in xml_files]\n",
    "    df = pd.DataFrame(list(zip(corpus_name, tags_)), columns = ['corpus_name','tags'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698356b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(df):\n",
    "    # prendre la liste des tags + l'intersection de toutes les listes\n",
    "    lists_tags = df['tags'].tolist()\n",
    "    results_union = set().union(*lists_tags)\n",
    "    # trouver les différences entre l'intersection de toutes les listes et la liste des tags d'un corpus donné\n",
    "    df['is_same'] = df['tags'].apply(lambda x:is_same(x, results_union))\n",
    "    return results_union, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(list1, list2):\n",
    "    s = set(list1)\n",
    "    difference = [x for x in list2 if x not in s]\n",
    "    if difference : \n",
    "        return difference\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61063a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_files_cnrtl = [r'{}\\{}.trs'.format(x, y).replace('\\\\','/') for x,y in list(zip(df_cnrtl['corpus'].tolist(), df_cnrtl['corpus_name'].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl_tagstrs = get_df_tags(trs_files_cnrtl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c9729",
   "metadata": {},
   "source": [
    "Comparaison des tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_union_trs, df_cnrtl_tagstrs = get_difference(df_cnrtl_tagstrs)\n",
    "print('Nb de tags communs :', len(results_union_trs), '\\n Liste des tags communs :\\n', results_union_trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl_tagstrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcd116",
   "metadata": {},
   "source": [
    "Tous les fichiers trs ont les mêmes tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4fd06",
   "metadata": {},
   "source": [
    "# Parsage fichier .trs \n",
    "\n",
    "1. extrait toutes les données du fichier .trs (possible de récupérer également des données qui n'apparaissent pas dans le dataframe final, comme le topic)\n",
    "2. Output un dataframe pour chaque fichier .trs avec à chaque ligne un tour de parole, son début, sa fin, le locuteur et ses caractéristiques, le fichier audio, l'encoding et *le texte synchronisé*\n",
    "\n",
    "*NB : le texte synchronisé n'est pas encore optimal, j'ai du mal à récupérer le texte entre deux balises Sync, car d'autres balises Event sont aussi utilisées + l'encodage est tjrs en iso*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689dc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding2(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding'] \n",
    "    # Open the file with the detected encoding\n",
    "    with open(file, 'r', encoding=encoding) as f:\n",
    "        soup = BeautifulSoup(f, \"lxml-xml\")\n",
    "    return soup, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trs2(file):\n",
    "    try : \n",
    "        transcription = [\"nom_fichier\", \"transcripteur\",\"reviseur\",\"format\", \"nombre_mots\", \"convention_transcription\"]\n",
    "        referencement = [\"nom_corpus\", \"responsable\", \"titre\", \"laboratoire\"]\n",
    "        locuteur_tag = ['age','sexe','etude','formation','profession_actuelle','profession_anterieure','role','degre','statut_francais','autre_langue','relation_locuteur','naissance','residence','appartenance','particularite','nombre_mots','temps_parole']\n",
    "        soup, encoding = detect_encoding2(file)\n",
    "        my_dict = {}\n",
    "        dict_trans, audio_filename = get_trans2(soup, my_dict)\n",
    "        my_dict.update(dict_trans)  \n",
    "        dict_loc = get_speaker2(soup, my_dict)\n",
    "        my_dict.update(dict_loc)\n",
    "        my_dict.update(get_topics2(soup, my_dict))\n",
    "        my_dict.update(get_section2(soup, my_dict))\n",
    "        dict_turns = get_turn2(soup)\n",
    "        df = pd.DataFrame.from_dict(dict_turns,orient='index')\n",
    "        df['audio_filename']= audio_filename\n",
    "        df['encoding']=encoding\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac80603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans2(soup, my_dict):\n",
    "    trans = soup.find('Trans')\n",
    "    # create a dictionary of locuteurs\n",
    "    if trans is not None:\n",
    "        audio_filename = trans.get('audio_filename')\n",
    "        my_dict['audio_filename'] = audio_filename\n",
    "    return my_dict, audio_filename\n",
    "\n",
    "def get_speaker2(soup, my_dict):\n",
    "    speakers = soup.find_all('Speaker')\n",
    "    # create a dictionary of speakers\n",
    "    for speaker in speakers:\n",
    "        scope = speaker.get('scope')\n",
    "        accent = speaker.get('accent')\n",
    "        dialect = speaker.get('dialect')\n",
    "        check = speaker.get('check')\n",
    "        name = speaker.get('name')\n",
    "        id_ = speaker.get('id')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_locuteur = {}\n",
    "        dict_locuteur['scope'] = scope\n",
    "        dict_locuteur['accent'] = accent\n",
    "        dict_locuteur['dialect'] = dialect\n",
    "        dict_locuteur['check'] = check\n",
    "        dict_locuteur['name'] = name\n",
    "        dict_locuteur['id'] = id_\n",
    "        my_dict[id_] = dict_locuteur\n",
    "    return my_dict\n",
    "\n",
    "def get_topics2(soup, my_dict):\n",
    "    topics = soup.find_all('Topic')\n",
    "    # create a dictionary of locuteurs\n",
    "    for topic in topics:\n",
    "        id_ = topic.get('id')\n",
    "        desc = topic.get('desc')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_topic = {}\n",
    "        dict_topic['desc'] = desc\n",
    "        dict_topic['id'] = id_\n",
    "        my_dict[id_] = dict_topic\n",
    "    return my_dict\n",
    "\n",
    "def get_section2(soup, my_dict):\n",
    "    sections = soup.find_all('Section')\n",
    "    # create a dictionary of locuteurs\n",
    "    for section in sections:\n",
    "        topic = section.get('topic')\n",
    "        endTime = section.get('endTime')\n",
    "        startTime = section.get('startTime')\n",
    "        type_ = section.get('type')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_section = {}\n",
    "        dict_section['topic'] = topic\n",
    "        dict_section['endTime'] = endTime\n",
    "        dict_section['startTime'] = startTime\n",
    "        dict_section['type'] = type_\n",
    "        my_dict['section_{}'.format(topic)] = dict_section\n",
    "    return my_dict\n",
    "\n",
    "def get_turn2(soup):\n",
    "    turns = soup.find_all('Turn')\n",
    "    dict_turns = {}\n",
    "    dict_loc = {}\n",
    "    dict_loc.update(get_speaker2(soup, dict_loc))\n",
    "    results = []\n",
    "    for index, turn in enumerate(turns):\n",
    "        endTime = turn.get('endTime')\n",
    "        startTime = turn.get('startTime')\n",
    "        speaker = turn.get('speaker')\n",
    "        sync_tags = turn.find_all('Sync')\n",
    "        result = get_sync_times2(turn)\n",
    "        text = turn.text.encode('iso-8859-1').decode('utf-8')\n",
    "        dict_turn = {}\n",
    "        dict_turn['startTime']=startTime\n",
    "        dict_turn['endTime']=endTime\n",
    "        dict_turn['speaker'] = speaker\n",
    "        dict_turn['speaker_characteristic'] = dict_loc.get('{}'.format(speaker))\n",
    "        dict_turn['text']= text.replace('\\n','')\n",
    "        dict_turn['text_synchronisé'] = result\n",
    "        dict_turns['{}'.format(index)] = dict_turn\n",
    "    return dict_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sync_times(turn):\n",
    "    sync_tags = turn.find_all('Sync')\n",
    "    sync_times = [float(sync_tag['time']) for sync_tag in sync_tags]\n",
    "    text = turn.get_text().replace('\\n\\n','\\n').strip().splitlines()\n",
    "    result = [(sync_time, text) for sync_time, text in list(zip(sync_times, text))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sync_times2(turn):\n",
    "    sync_tags = turn.find_all('Sync')\n",
    "    list_sync = []\n",
    "    for i, sync_tag in enumerate(sync_tags):  \n",
    "        contenu = []\n",
    "        # Récupérer le contenu jusqu'à la balise Sync suivante\n",
    "        current_tag = sync_tag.next_sibling\n",
    "        while current_tag is not None and current_tag.name != 'Sync':\n",
    "            if isinstance(current_tag, NavigableString):\n",
    "                current_tag_str = current_tag.get_text().replace('\\n','').encode('iso-8859-1').decode('utf-8')\n",
    "                contenu.append(current_tag_str)\n",
    "            else:\n",
    "                pass\n",
    "            current_tag = current_tag.next_sibling\n",
    "        list_sync.append((sync_tag['time'], ' '.join(contenu)))\n",
    "    return list_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc14ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_trs2(trs_files_cnrtl[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_files_cnrtl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b08243",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_turn= [parse_trs2(file) for file in trs_files_cnrtl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_essai = list_df_turn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5589bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta(df_essai, dict_meta, dict_path):\n",
    "    try:\n",
    "        nom = df_essai['audio_filename'].tolist()[0].replace('.wav', '')\n",
    "        df_essai['speaker_name'] = df_essai.apply(lambda row: row['speaker_characteristic']['name'], axis=1)\n",
    "        df_essai['speaker_native'] = df_essai.apply(lambda row: row['speaker_characteristic']['dialect'], axis=1)\n",
    "        nom = df_essai['audio_filename'][0].replace('.wav', '')\n",
    "        dict_corpus = dict_meta['{}'.format(nom)]\n",
    "        dict_loc = dict_corpus['locuteur']\n",
    "        df_essai['sexe_speaker'] = df_essai.apply(lambda row: get_sexe(dict_meta, nom), axis=1)\n",
    "        df_essai['age_speaker'] = df_essai.apply(lambda row: get_age(dict_meta, nom), axis=1)\n",
    "        df_essai['profession_speaker'] = df_essai.apply(lambda row: get_prof(dict_meta, nom), axis=1)\n",
    "\n",
    "\n",
    "        description = dict_corpus['resume']\n",
    "        duree = dict_corpus['duree']\n",
    "        genre = dict_corpus['genre']\n",
    "        date_enregistrement = dict_corpus['date']\n",
    "        responsable = str(dict_corpus['responsable_corpus']) +' '+ str(dict_corpus['responsable'])\n",
    "        langue_enregistrement = 'français'\n",
    "        lieu_enregistrement = str(dict_corpus['pays']) +' '+ str(dict_corpus['region']) + str(dict_corpus['ville'])\n",
    "\n",
    "        df_essai['description'] = genre + ' '+ description\n",
    "        df_essai['duree'] = duree \n",
    "        df_essai['responsable'] = responsable\n",
    "        df_essai['date_enregistrement'] = date_enregistrement \n",
    "        df_essai['langue_enregistrement'] = langue_enregistrement \n",
    "        df_essai['lieu_enregistrement'] = lieu_enregistrement \n",
    "        \n",
    "        path_trs = str(dict_path['{}'.format(nom)]['corpus'])+'\\\\'+str(dict_path['{}'.format(nom)]['trs'])\n",
    "        path_wav = str(dict_path['{}'.format(nom)]['corpus'])+'\\\\'+str(dict_path['{}'.format(nom)]['wav'])\n",
    "        \n",
    "        df_essai['path_trs'] = path_trs\n",
    "        df_essai['path_wav'] = path_wav\n",
    "        df_essai['sous_corpus']=nom\n",
    "\n",
    "        return df_essai\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_meta = df_cnrtl_metadonnees.set_index('nomDossier').T.to_dict('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c463c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = df_cnrtl.set_index('corpus_name').T.to_dict('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(dict_meta, nom):\n",
    "    for x, y  in dict_meta['{}'.format(nom)]['locuteur']:\n",
    "        if x == L : #['{}'.format(L)]#['sexe']\n",
    "            age = y['age']\n",
    "            return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sexe(dict_meta, nom):\n",
    "    for x, y  in dict_meta['{}'.format(nom)]['locuteur']:\n",
    "        if x == L : #['{}'.format(L)]#['sexe']\n",
    "            sexe = y['sexe']\n",
    "            return sexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prof(dict_meta, nom):\n",
    "    for x, y  in dict_meta['{}'.format(nom)]['locuteur']:\n",
    "        if x == L : #['{}'.format(L)]#['sexe']\n",
    "            prof = y['profession_actuelle']\n",
    "            return prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aeecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [add_meta(df, dict_meta, dict_path) for df in list_df_turn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tours = pd.concat(final)\n",
    "df_tours['corpus'] = ['TCOF']*len(df_tours)\n",
    "df_tours['speaker']=df_tours['speaker_name']\n",
    "df_tours = df_tours.drop('speaker_characteristic', axis=1)\n",
    "df_tours = df_tours.drop('audio_filename', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713fe8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tours.to_csv('E:\\Corpus\\TCOF_CNRTL\\TCOF_TOTAL.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981e0876",
   "metadata": {},
   "source": [
    "# Traitement du corpus TCOF - CNRTL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f33e2",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "923f845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec235b",
   "metadata": {},
   "source": [
    "# **Téléchargement des corpus depuis le site CNRTL**\n",
    "\n",
    "1. Depuis le site du CNRTL, télécharge chaque corpus dans un fichier compressé .zip (avec les fichiers .trs, .xml, .wav), dans le dossier indiqué par la variable filename\n",
    "2. nomme chaque fichier compressé le nom du corpus, récupéré depuis la page html du site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54577545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_name_cnrtl(number):\n",
    "    url = \"https://tcof.atilf.fr/index.php?r=corpus%2Fview&id={}\".format(number)\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    # Find the h1 tag and extract its text\n",
    "    h1_tag = soup.find('h1')\n",
    "    text = h1_tag.get_text()\n",
    "    # Extract the corpus name from the text\n",
    "    corpus_name = text.replace('Corpus ', '')\n",
    "    return corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,800):\n",
    "    try:\n",
    "        url = 'https://tcof.atilf.fr/index.php?r=corpus/download-corpus&id={}'.format(i)\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            filename = 'E:/Corpus/TCOF_CNRTL/{}.zip'.format(corpus_name_cnrtl(i))\n",
    "            with open(filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31d4bf",
   "metadata": {},
   "source": [
    "# **Fichiers dans le dossier**\n",
    "> **Avant de lancer**: dézipper manuellement tous les fichier zip \n",
    "\n",
    "Le script : \n",
    "1. Recense les fichiers existants pour chaque corpus\n",
    "2. Output un dataframe avec pour chaque corpus, les fichiers existants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef11fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_cnrtl(path):\n",
    "    list_corpus_path = [add_path2corpus(path, corpus) for corpus in get_all_folder(path)]\n",
    "    mydict = {}\n",
    "    for corpus_path in list_corpus_path:\n",
    "        dict_corpus = get_corpus_files(corpus_path)\n",
    "        mydict[corpus_path]=dict_corpus\n",
    "    df = pd.DataFrame.from_dict(mydict, orient='index').rename_axis('corpus').reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7701dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_files(path):\n",
    "    files = {}\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.xml'):\n",
    "            files['xml']=file\n",
    "        if file.endswith('.trs'):\n",
    "            pattern = r'(anonymise_[\\S]*.trs)'\n",
    "            match = re.search(pattern, file)\n",
    "            if match:\n",
    "                files['anonymise_trs']=file\n",
    "            else:\n",
    "                files['trs']=file\n",
    "        if file.endswith('.wav'):\n",
    "            pattern = r'(anonymise_[\\S]*.wav)'\n",
    "            match = re.search(pattern, file)\n",
    "            if match:\n",
    "                files['anonymise_wav']=file\n",
    "            else:\n",
    "                files['wav']=file\n",
    "        else:\n",
    "            continue\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bebc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path2corpus(path,corpus):\n",
    "    new = '{}\\{}'.format(path, corpus)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38fcc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_folder(path):\n",
    "    directory = os.listdir(path)\n",
    "    folder_list = []\n",
    "    for folder in directory:\n",
    "        if os.path.isdir(os.path.join(path, folder)):\n",
    "            folder_list.append(folder)\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3246a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_corpus_names_col(df):\n",
    "    wav = df['xml'].tolist()\n",
    "    corpus_names = []\n",
    "    for file in wav:\n",
    "        try: \n",
    "            pattern = r'^(.*)\\.xml$'\n",
    "            match = re.search(pattern, file)\n",
    "            if match:\n",
    "                corpus = match.group(1)\n",
    "        except:\n",
    "            corpus = 'NAN'\n",
    "        corpus_names.append(corpus)\n",
    "    df['corpus_name'] = corpus_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d793c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre le chemin du dossier \n",
    "path_cnrtl = r'E:\\Corpus\\TCOF_CNRTL'\n",
    "#obtenir le dataframe avec le noms des fichiers du dossier dedans\n",
    "df_cnrtl = get_files_cnrtl(path_cnrtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38939531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl = add_corpus_names_col(df_cnrtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4398b34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>xml</th>\n",
       "      <th>wav</th>\n",
       "      <th>trs</th>\n",
       "      <th>anonymise_wav</th>\n",
       "      <th>anonymise_trs</th>\n",
       "      <th>corpus_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\theorielinguistique_07</td>\n",
       "      <td>theorielinguistique_07.xml</td>\n",
       "      <td>theorielinguistique_07.wav</td>\n",
       "      <td>theorielinguistique_07.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theorielinguistique_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\testssncf_qab_12</td>\n",
       "      <td>testssncf_qab_12.xml</td>\n",
       "      <td>testssncf_qab_12.wav</td>\n",
       "      <td>testssncf_qab_12.trs</td>\n",
       "      <td>anonymise_testssncf_qab_12.wav</td>\n",
       "      <td>anonymise_testssncf_qab_12.trs</td>\n",
       "      <td>testssncf_qab_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\theatre_fle_11</td>\n",
       "      <td>theatre_fle_11.xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theatre_fle_11.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theatre_fle_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\telephone_lam_13</td>\n",
       "      <td>telephone_lam_13.xml</td>\n",
       "      <td>telephone_lam_13.wav</td>\n",
       "      <td>telephone_lam_13.trs</td>\n",
       "      <td>anonymise_telephone_lam_13.wav</td>\n",
       "      <td>anonymise_telephone_lam_13.trs</td>\n",
       "      <td>telephone_lam_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\tel_maz_07</td>\n",
       "      <td>tel_maz_07.xml</td>\n",
       "      <td>tel_maz_07.wav</td>\n",
       "      <td>tel_maz_07.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tel_maz_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\thibaut1_der</td>\n",
       "      <td>thibaut1_der.xml</td>\n",
       "      <td>thibaut1_der.wav</td>\n",
       "      <td>thibaut1_der.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thibaut1_der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\thibault1_lev</td>\n",
       "      <td>thibault1_lev.xml</td>\n",
       "      <td>thibault1_lev.wav</td>\n",
       "      <td>thibault1_lev.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thibault1_lev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\thibault1_cor</td>\n",
       "      <td>thibault1_cor.xml</td>\n",
       "      <td>thibault1_cor.wav</td>\n",
       "      <td>thibault1_cor.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thibault1_cor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\thibaud1_son</td>\n",
       "      <td>thibaud1_son.xml</td>\n",
       "      <td>thibaud1_son.wav</td>\n",
       "      <td>thibaud1_son.trs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thibaud1_son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>E:\\Corpus\\TCOF_CNRTL\\these_pit_09</td>\n",
       "      <td>these_pit_09.xml</td>\n",
       "      <td>these_pit_09.wav</td>\n",
       "      <td>these_pit_09.trs</td>\n",
       "      <td>anonymise_these_pit_09.wav</td>\n",
       "      <td>anonymise_these_pit_09.trs</td>\n",
       "      <td>these_pit_09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          corpus                         xml  \\\n",
       "0    E:\\Corpus\\TCOF_CNRTL\\theorielinguistique_07  theorielinguistique_07.xml   \n",
       "1          E:\\Corpus\\TCOF_CNRTL\\testssncf_qab_12        testssncf_qab_12.xml   \n",
       "2            E:\\Corpus\\TCOF_CNRTL\\theatre_fle_11          theatre_fle_11.xml   \n",
       "3          E:\\Corpus\\TCOF_CNRTL\\telephone_lam_13        telephone_lam_13.xml   \n",
       "4                E:\\Corpus\\TCOF_CNRTL\\tel_maz_07              tel_maz_07.xml   \n",
       "..                                           ...                         ...   \n",
       "584            E:\\Corpus\\TCOF_CNRTL\\thibaut1_der            thibaut1_der.xml   \n",
       "585           E:\\Corpus\\TCOF_CNRTL\\thibault1_lev           thibault1_lev.xml   \n",
       "586           E:\\Corpus\\TCOF_CNRTL\\thibault1_cor           thibault1_cor.xml   \n",
       "587            E:\\Corpus\\TCOF_CNRTL\\thibaud1_son            thibaud1_son.xml   \n",
       "588            E:\\Corpus\\TCOF_CNRTL\\these_pit_09            these_pit_09.xml   \n",
       "\n",
       "                            wav                         trs  \\\n",
       "0    theorielinguistique_07.wav  theorielinguistique_07.trs   \n",
       "1          testssncf_qab_12.wav        testssncf_qab_12.trs   \n",
       "2                           NaN          theatre_fle_11.trs   \n",
       "3          telephone_lam_13.wav        telephone_lam_13.trs   \n",
       "4                tel_maz_07.wav              tel_maz_07.trs   \n",
       "..                          ...                         ...   \n",
       "584            thibaut1_der.wav            thibaut1_der.trs   \n",
       "585           thibault1_lev.wav           thibault1_lev.trs   \n",
       "586           thibault1_cor.wav           thibault1_cor.trs   \n",
       "587            thibaud1_son.wav            thibaud1_son.trs   \n",
       "588            these_pit_09.wav            these_pit_09.trs   \n",
       "\n",
       "                      anonymise_wav                   anonymise_trs  \\\n",
       "0                               NaN                             NaN   \n",
       "1    anonymise_testssncf_qab_12.wav  anonymise_testssncf_qab_12.trs   \n",
       "2                               NaN                             NaN   \n",
       "3    anonymise_telephone_lam_13.wav  anonymise_telephone_lam_13.trs   \n",
       "4                               NaN                             NaN   \n",
       "..                              ...                             ...   \n",
       "584                             NaN                             NaN   \n",
       "585                             NaN                             NaN   \n",
       "586                             NaN                             NaN   \n",
       "587                             NaN                             NaN   \n",
       "588      anonymise_these_pit_09.wav      anonymise_these_pit_09.trs   \n",
       "\n",
       "                corpus_name  \n",
       "0    theorielinguistique_07  \n",
       "1          testssncf_qab_12  \n",
       "2            theatre_fle_11  \n",
       "3          telephone_lam_13  \n",
       "4                tel_maz_07  \n",
       "..                      ...  \n",
       "584            thibaut1_der  \n",
       "585           thibault1_lev  \n",
       "586           thibault1_cor  \n",
       "587            thibaud1_son  \n",
       "588            these_pit_09  \n",
       "\n",
       "[589 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#liste de tous les fichiers pour chaque corpus\n",
    "df_cnrtl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90996490",
   "metadata": {},
   "source": [
    "# **Extraction des métadonnées (fichier .xml)**\n",
    "\n",
    "1. Extrait toutes les métadonnées depuis le fichier .xml\n",
    "2. Détecte si le fichier est encodé en utf8 ou iso, et le décode selon le format.\n",
    "2. Output un dataframe avec pour chaque corpus, les métadonnées associées extraites depuis le fichier .xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2b272c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding'] \n",
    "    # Open the file with the detected encoding\n",
    "    with open(file, 'r', encoding=encoding) as f:\n",
    "        soup = BeautifulSoup(f, \"lxml-xml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c0ce07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml2df(xml_files):\n",
    "    list_df =  []\n",
    "    for xml_file in xml_files:\n",
    "        soup = detect_encoding(xml_file)\n",
    "        dict_file, locuteur = parsexml(soup)\n",
    "        df_corpus = get_df(dict_file)\n",
    "        locuteur_list = list(locuteur.items())\n",
    "        df_corpus['locuteur'] = [locuteur_list] * len(df_corpus)\n",
    "        list_df.append(df_corpus)\n",
    "    df = pd.concat(list_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e72414e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(my_dict):\n",
    "    dict2df_corpus = my_dict.copy()\n",
    "    df_corpus = pd.DataFrame([dict2df_corpus])\n",
    "    return df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc1b862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general(soup, my_dict, general):\n",
    "    for tag_name in general:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_enregistrement(soup, my_dict, enregistrement):\n",
    "    for tag_name in enregistrement:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_referencement(soup, my_dict, referencement):\n",
    "    for tag_name in referencement:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_transcription(soup, my_dict, transcription):\n",
    "    for tag_name in transcription:\n",
    "        tag = soup.find(tag_name)\n",
    "        if tag is not None:\n",
    "            tag_value = tag.text.strip()\n",
    "            tag_name = tag.name\n",
    "            my_dict[tag_name] = tag_value\n",
    "    return my_dict\n",
    "\n",
    "def get_locuteurs(soup, my_dict, locuteur_tag):\n",
    "    # get all locuteurs\n",
    "    locuteurs = soup.find_all('locuteur')\n",
    "\n",
    "    # create a dictionary of locuteurs\n",
    "    for locuteur in locuteurs[1:]:\n",
    "        loc_principal = locuteur.get('locuteurPrincipal')\n",
    "        loc_nb_tour = locuteur.get('nombre_tours')\n",
    "        loc_identifiant = locuteur.get('identifiant')\n",
    "\n",
    "        # create a new dictionary for this locuteur\n",
    "        dict_locuteur = {}\n",
    "        dict_locuteur['nb_tour'] = loc_nb_tour\n",
    "        dict_locuteur['locuteur_principal'] = loc_principal\n",
    "\n",
    "        for tag_name in locuteur_tag:\n",
    "            tag = locuteur.find(tag_name)\n",
    "            if tag is not None:\n",
    "                tag_value = tag.text.strip()\n",
    "                tag_name = tag.name\n",
    "                dict_locuteur[tag_name] = tag_value\n",
    "        # add this locuteur to the dictionary\n",
    "        my_dict[loc_identifiant] = dict_locuteur\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01a29218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsexml(soup):\n",
    "    general = [\"nomDossier\", \"responsable_corpus\",\"droit_acces\",\"lien_autre_corpus\",\"mail\",'logiciel_alignement','anonymisation',\"nombre_locuteurs\",\"relation\",\"type_corpus\",\"modalite_recueil\",\"canal\",\"cadre\",\"degre\",'situation_enonciation',\"genre\",\"support_dialogue\",\"document_annexe\",\"resume\",\"commentaire\",\"createur_fiche\",'date_creation_fiche']\n",
    "    enregistrement = [\"nom_fichier\", \"responsable\", \"autorisation\", \"qualite\",\"taille\",\"duree\",\"date\",\"duree_transcription\",\"debut_timecode_transcription\", \"dernier_timecode_transcription\", \"pays\",\"region\",\"ville\",\"arrondissement\", \"description_lieu\",\"format\"]\n",
    "    transcription = [\"nom_fichier\", \"transcripteur\",\"reviseur\",\"format\", \"nombre_mots\", \"convention_transcription\"]\n",
    "    referencement = [\"nom_corpus\", \"responsable\", \"titre\", \"laboratoire\"]\n",
    "    locuteur_tag = ['age','sexe','etude','formation','profession_actuelle','profession_anterieure','role','degre','statut_francais','autre_langue','relation_locuteur','naissance','residence','appartenance','particularite','nombre_mots','temps_parole']\n",
    "    my_dict = {}\n",
    "    my_dict.update(get_general(soup, my_dict, general))\n",
    "    my_dict.update(get_enregistrement(soup, my_dict, enregistrement))\n",
    "    my_dict.update(get_transcription(soup, my_dict,transcription))\n",
    "    my_dict.update(get_referencement(soup, my_dict, referencement))\n",
    "    locuteur = {}\n",
    "    dict_locuteur = get_locuteurs(soup, locuteur, locuteur_tag)\n",
    "    #my_dict.update(get_locuteurs(soup, my_dict, locuteur_tag))\n",
    "    return my_dict, dict_locuteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e834de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files_cnrtl = [r'{}\\{}.xml'.format(x, y).replace('\\\\','/') for x,y in list(zip(df_cnrtl['corpus'].tolist(), df_cnrtl['corpus_name'].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d9d88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl_metadonnees = xml2df(xml_files_cnrtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb6a0cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomDossier</th>\n",
       "      <th>responsable_corpus</th>\n",
       "      <th>droit_acces</th>\n",
       "      <th>mail</th>\n",
       "      <th>logiciel_alignement</th>\n",
       "      <th>anonymisation</th>\n",
       "      <th>nombre_locuteurs</th>\n",
       "      <th>relation</th>\n",
       "      <th>type_corpus</th>\n",
       "      <th>modalite_recueil</th>\n",
       "      <th>...</th>\n",
       "      <th>description_lieu</th>\n",
       "      <th>format</th>\n",
       "      <th>transcripteur</th>\n",
       "      <th>reviseur</th>\n",
       "      <th>nombre_mots</th>\n",
       "      <th>convention_transcription</th>\n",
       "      <th>nom_corpus</th>\n",
       "      <th>titre</th>\n",
       "      <th>laboratoire</th>\n",
       "      <th>locuteur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theorielinguistique_07</td>\n",
       "      <td>Virginie André</td>\n",
       "      <td>Libre</td>\n",
       "      <td>virginie.andre@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>3</td>\n",
       "      <td>professionnelle</td>\n",
       "      <td>entre adultes</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2423</td>\n",
       "      <td>2008</td>\n",
       "      <td>theorielinguistique_07</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(L1, {'nb_tour': '66', 'locuteur_principal': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>testssncf_qab_12</td>\n",
       "      <td>Virginie André</td>\n",
       "      <td>Libre</td>\n",
       "      <td>virginie.andre@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>lien de parenté</td>\n",
       "      <td>entre adultes</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>MICHEL Annlyse, QABICE Fanny</td>\n",
       "      <td>NASSAU Guillaume</td>\n",
       "      <td>3086</td>\n",
       "      <td>2008</td>\n",
       "      <td>testssncf_qab_12</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(L1, {'nb_tour': '70', 'locuteur_principal': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theatre_fle_11</td>\n",
       "      <td>Virginie André</td>\n",
       "      <td>Libre</td>\n",
       "      <td>virginie.andre@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>8</td>\n",
       "      <td>lien amical</td>\n",
       "      <td>entre adultes</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>FLEURANCE Clémentine, THOMARDEL Camille, GIRAR...</td>\n",
       "      <td>NASSAU Guillaume</td>\n",
       "      <td>3859</td>\n",
       "      <td>2008</td>\n",
       "      <td>theatre_fle_11</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(L1, {'nb_tour': '22', 'locuteur_principal': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>telephone_lam_13</td>\n",
       "      <td>Virginie André</td>\n",
       "      <td>Libre</td>\n",
       "      <td>virginie.andre@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>lien de parenté</td>\n",
       "      <td>entre adultes</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>LAMBERT LUCIE</td>\n",
       "      <td>NASSAU Guillaume</td>\n",
       "      <td>2372</td>\n",
       "      <td>2008</td>\n",
       "      <td>telephone_lam_13</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(L1, {'nb_tour': '90', 'locuteur_principal': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tel_maz_07</td>\n",
       "      <td>Virginie André</td>\n",
       "      <td>Libre</td>\n",
       "      <td>Virginie.Andre@univ-nancy2.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>lien amical</td>\n",
       "      <td>entre adultes</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>Mazoyer Mathilde, Gabrion Julie</td>\n",
       "      <td>Stéphanie Houin</td>\n",
       "      <td>1169</td>\n",
       "      <td>2008</td>\n",
       "      <td>tel_maz_07</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(L1, {'nb_tour': '46', 'locuteur_principal': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thibaut1_der</td>\n",
       "      <td>Emmanuelle Canut</td>\n",
       "      <td>Libre</td>\n",
       "      <td>emmanuelle.canut@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>connaissance</td>\n",
       "      <td>adulte-enfant</td>\n",
       "      <td>Sollicitées par un chercheur</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>Dereniowski Catherine</td>\n",
       "      <td>G. Nassau</td>\n",
       "      <td>2459</td>\n",
       "      <td>2008</td>\n",
       "      <td>thibaut1_der</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(Adulte, {'nb_tour': '77', 'locuteur_principa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thibault1_lev</td>\n",
       "      <td>Emmanuelle Canut</td>\n",
       "      <td>Libre</td>\n",
       "      <td>emmanuelle.canut@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>connaissance</td>\n",
       "      <td>adulte-enfant</td>\n",
       "      <td>Sollicitées par un chercheur</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>Y.Sow</td>\n",
       "      <td>E.Canut</td>\n",
       "      <td>940</td>\n",
       "      <td>2008</td>\n",
       "      <td>thibault1_lev</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(Thibault, {'nb_tour': '71', 'locuteur_princi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thibault1_cor</td>\n",
       "      <td>Emmanuelle Canut</td>\n",
       "      <td>Libre</td>\n",
       "      <td>emmanuelle.canut@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>connaissance</td>\n",
       "      <td>adulte-enfant</td>\n",
       "      <td>Sollicitées par un chercheur</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>Y.Sow</td>\n",
       "      <td>E.Canut</td>\n",
       "      <td>728</td>\n",
       "      <td>2008</td>\n",
       "      <td>thibault1_cor</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(Adulte, {'nb_tour': '88', 'locuteur_principa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thibaud1_son</td>\n",
       "      <td>Emmanuelle Canut</td>\n",
       "      <td>Libre</td>\n",
       "      <td>emmanuelle.canut@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>2</td>\n",
       "      <td>connaissance</td>\n",
       "      <td>adulte-enfant</td>\n",
       "      <td>Sollicitées par un chercheur</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>Huguin, Sontag Eugénie</td>\n",
       "      <td>G. Nassau</td>\n",
       "      <td>1067</td>\n",
       "      <td>2008</td>\n",
       "      <td>thibaud1_son</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(Adulte, {'nb_tour': '55', 'locuteur_principa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>these_pit_09</td>\n",
       "      <td>Virginie André</td>\n",
       "      <td>Libre</td>\n",
       "      <td>virginie.andre@univ-lorraine.fr</td>\n",
       "      <td>Transcriber</td>\n",
       "      <td>Son + transcription\\nBip</td>\n",
       "      <td>1</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>entre adultes</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Wav</td>\n",
       "      <td>Caroline PITOY</td>\n",
       "      <td></td>\n",
       "      <td>2169</td>\n",
       "      <td>2008</td>\n",
       "      <td>these_pit_09</td>\n",
       "      <td>TCOF</td>\n",
       "      <td>ATILF</td>\n",
       "      <td>[(L1, {'nb_tour': '1', 'locuteur_principal': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                nomDossier responsable_corpus droit_acces  \\\n",
       "0   theorielinguistique_07     Virginie André       Libre   \n",
       "0         testssncf_qab_12     Virginie André       Libre   \n",
       "0           theatre_fle_11     Virginie André       Libre   \n",
       "0         telephone_lam_13     Virginie André       Libre   \n",
       "0               tel_maz_07     Virginie André       Libre   \n",
       "..                     ...                ...         ...   \n",
       "0             thibaut1_der   Emmanuelle Canut       Libre   \n",
       "0            thibault1_lev   Emmanuelle Canut       Libre   \n",
       "0            thibault1_cor   Emmanuelle Canut       Libre   \n",
       "0             thibaud1_son   Emmanuelle Canut       Libre   \n",
       "0             these_pit_09     Virginie André       Libre   \n",
       "\n",
       "                                 mail logiciel_alignement  \\\n",
       "0     virginie.andre@univ-lorraine.fr         Transcriber   \n",
       "0     virginie.andre@univ-lorraine.fr         Transcriber   \n",
       "0     virginie.andre@univ-lorraine.fr         Transcriber   \n",
       "0     virginie.andre@univ-lorraine.fr         Transcriber   \n",
       "0       Virginie.Andre@univ-nancy2.fr         Transcriber   \n",
       "..                                ...                 ...   \n",
       "0   emmanuelle.canut@univ-lorraine.fr         Transcriber   \n",
       "0   emmanuelle.canut@univ-lorraine.fr         Transcriber   \n",
       "0   emmanuelle.canut@univ-lorraine.fr         Transcriber   \n",
       "0   emmanuelle.canut@univ-lorraine.fr         Transcriber   \n",
       "0     virginie.andre@univ-lorraine.fr         Transcriber   \n",
       "\n",
       "               anonymisation nombre_locuteurs         relation    type_corpus  \\\n",
       "0   Son + transcription\\nBip                3  professionnelle  entre adultes   \n",
       "0   Son + transcription\\nBip                2  lien de parenté  entre adultes   \n",
       "0   Son + transcription\\nBip                8      lien amical  entre adultes   \n",
       "0   Son + transcription\\nBip                2  lien de parenté  entre adultes   \n",
       "0   Son + transcription\\nBip                2      lien amical  entre adultes   \n",
       "..                       ...              ...              ...            ...   \n",
       "0   Son + transcription\\nBip                2     connaissance  adulte-enfant   \n",
       "0   Son + transcription\\nBip                2     connaissance  adulte-enfant   \n",
       "0   Son + transcription\\nBip                2     connaissance  adulte-enfant   \n",
       "0   Son + transcription\\nBip                2     connaissance  adulte-enfant   \n",
       "0   Son + transcription\\nBip                1         inconnue  entre adultes   \n",
       "\n",
       "                modalite_recueil  ... description_lieu format  \\\n",
       "0                       Inconnue  ...                     Wav   \n",
       "0                       Inconnue  ...                     Wav   \n",
       "0                       Inconnue  ...                     Wav   \n",
       "0                       Inconnue  ...                     Wav   \n",
       "0                       Inconnue  ...                     Wav   \n",
       "..                           ...  ...              ...    ...   \n",
       "0   Sollicitées par un chercheur  ...                     Wav   \n",
       "0   Sollicitées par un chercheur  ...                     Wav   \n",
       "0   Sollicitées par un chercheur  ...                     Wav   \n",
       "0   Sollicitées par un chercheur  ...                     Wav   \n",
       "0                       Inconnue  ...                     Wav   \n",
       "\n",
       "                                        transcripteur          reviseur  \\\n",
       "0                                                                         \n",
       "0                        MICHEL Annlyse, QABICE Fanny  NASSAU Guillaume   \n",
       "0   FLEURANCE Clémentine, THOMARDEL Camille, GIRAR...  NASSAU Guillaume   \n",
       "0                                       LAMBERT LUCIE  NASSAU Guillaume   \n",
       "0                     Mazoyer Mathilde, Gabrion Julie   Stéphanie Houin   \n",
       "..                                                ...               ...   \n",
       "0                               Dereniowski Catherine         G. Nassau   \n",
       "0                                               Y.Sow           E.Canut   \n",
       "0                                               Y.Sow           E.Canut   \n",
       "0                              Huguin, Sontag Eugénie         G. Nassau   \n",
       "0                                      Caroline PITOY                     \n",
       "\n",
       "   nombre_mots convention_transcription              nom_corpus titre  \\\n",
       "0         2423                     2008  theorielinguistique_07  TCOF   \n",
       "0         3086                     2008        testssncf_qab_12  TCOF   \n",
       "0         3859                     2008          theatre_fle_11  TCOF   \n",
       "0         2372                     2008        telephone_lam_13  TCOF   \n",
       "0         1169                     2008              tel_maz_07  TCOF   \n",
       "..         ...                      ...                     ...   ...   \n",
       "0         2459                     2008            thibaut1_der  TCOF   \n",
       "0          940                     2008           thibault1_lev  TCOF   \n",
       "0          728                     2008           thibault1_cor  TCOF   \n",
       "0         1067                     2008            thibaud1_son  TCOF   \n",
       "0         2169                     2008            these_pit_09  TCOF   \n",
       "\n",
       "   laboratoire                                           locuteur  \n",
       "0        ATILF  [(L1, {'nb_tour': '66', 'locuteur_principal': ...  \n",
       "0        ATILF  [(L1, {'nb_tour': '70', 'locuteur_principal': ...  \n",
       "0        ATILF  [(L1, {'nb_tour': '22', 'locuteur_principal': ...  \n",
       "0        ATILF  [(L1, {'nb_tour': '90', 'locuteur_principal': ...  \n",
       "0        ATILF  [(L1, {'nb_tour': '46', 'locuteur_principal': ...  \n",
       "..         ...                                                ...  \n",
       "0        ATILF  [(Adulte, {'nb_tour': '77', 'locuteur_principa...  \n",
       "0        ATILF  [(Thibault, {'nb_tour': '71', 'locuteur_princi...  \n",
       "0        ATILF  [(Adulte, {'nb_tour': '88', 'locuteur_principa...  \n",
       "0        ATILF  [(Adulte, {'nb_tour': '55', 'locuteur_principa...  \n",
       "0        ATILF  [(L1, {'nb_tour': '1', 'locuteur_principal': '...  \n",
       "\n",
       "[589 rows x 45 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#liste des métadonnées de chaque corpus\n",
    "df_cnrtl_metadonnees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b029e4",
   "metadata": {},
   "source": [
    "# **Analyse des tag.names pour les fichier .trs**\n",
    "\n",
    "1. Récupère tous les noms des balises utilisées dans le fichier trs\n",
    "2. Compare les noms utilisés dans tous les corpus\n",
    "3. Output un dataframe avec pour chaque corpus, le fichier .trs correspondant, tous les tags utilisés, la différence avec les autres corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef065c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tagsname(xml_file):\n",
    "    # Parse the XML file into an ElementTree object\n",
    "    try : \n",
    "        tree = ET.parse(xml_file)\n",
    "    # Get the root element of the tree\n",
    "        root = tree.getroot()\n",
    "    # Initialize an empty set to store the tag names\n",
    "        tag_names = set()\n",
    "    # Iterate over all elements in the tree and add their tag names to the set\n",
    "        for elem in root.iter():\n",
    "            tag_names.add(elem.tag)\n",
    "    # Return the set of tag names\n",
    "    except: \n",
    "        return \"Pas de fichier trouvé à cet emplacement\"\n",
    "    return tag_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11fb9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_name(path):\n",
    "    filename = re.search(r'[^\\\\\\/]*?(?=\\.\\w+$)', path).group()\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90a0f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_tags(xml_files):\n",
    "    corpus_name = [get_corpus_name(xml_file) for xml_file in xml_files]\n",
    "    tags_ = [get_all_tagsname(xml_file) for xml_file in xml_files]\n",
    "    df = pd.DataFrame(list(zip(corpus_name, tags_)), columns = ['corpus_name','tags'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "698356b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(df):\n",
    "    # prendre la liste des tags + l'intersection de toutes les listes\n",
    "    lists_tags = df['tags'].tolist()\n",
    "    results_union = set().union(*lists_tags)\n",
    "    # trouver les différences entre l'intersection de toutes les listes et la liste des tags d'un corpus donné\n",
    "    df['is_same'] = df['tags'].apply(lambda x:is_same(results_union,x))\n",
    "    return results_union, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99c2a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(list1, list2):\n",
    "    s = set(list1)\n",
    "    difference = [x for x in list2 if x not in s]\n",
    "    if difference : \n",
    "        return difference\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f61063a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trs_files_cnrtl = [r'{}\\{}.trs'.format(x, y).replace('\\\\','/') for x,y in list(zip(df_cnrtl['corpus'].tolist(), df_cnrtl['corpus_name'].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0dcfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrtl_tagstrs = get_df_tags(trs_files_cnrtl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c9729",
   "metadata": {},
   "source": [
    "Comparaison des tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e16e10b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de tags communs : 12 \n",
      " Liste des tags communs :\n",
      " {'Sync', 'Trans', 'Topic', 'Turn', 'Section', 'Episode', 'Topics', 'Speaker', 'Who', 'Comment', 'Event', 'Speakers'}\n"
     ]
    }
   ],
   "source": [
    "results_union_trs, df_cnrtl_tagstrs = get_difference(df_cnrtl_tagstrs)\n",
    "print('Nb de tags communs :', len(results_union_trs), '\\n Liste des tags communs :\\n', results_union_trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4608b058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>is_same</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>theorielinguistique_07</td>\n",
       "      <td>{Sync, Trans, Speaker, Turn, Section, Comment,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>testssncf_qab_12</td>\n",
       "      <td>{Sync, Trans, Speaker, Turn, Section, Comment,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theatre_fle_11</td>\n",
       "      <td>{Sync, Trans, Speaker, Turn, Section, Comment,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>telephone_lam_13</td>\n",
       "      <td>{Sync, Trans, Speaker, Turn, Section, Episode,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tel_maz_07</td>\n",
       "      <td>{Sync, Trans, Speaker, Turn, Section, Comment,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>thibaut1_der</td>\n",
       "      <td>{Sync, Topics, Trans, Speaker, Topic, Turn, Se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>thibault1_lev</td>\n",
       "      <td>{Sync, Topics, Trans, Speaker, Topic, Turn, Se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>thibault1_cor</td>\n",
       "      <td>{Sync, Topics, Trans, Speaker, Topic, Turn, Se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>thibaud1_son</td>\n",
       "      <td>{Sync, Topics, Trans, Speaker, Topic, Turn, Se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>these_pit_09</td>\n",
       "      <td>{Sync, Topics, Trans, Speaker, Topic, Turn, Se...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                corpus_name  \\\n",
       "0    theorielinguistique_07   \n",
       "1          testssncf_qab_12   \n",
       "2            theatre_fle_11   \n",
       "3          telephone_lam_13   \n",
       "4                tel_maz_07   \n",
       "..                      ...   \n",
       "584            thibaut1_der   \n",
       "585           thibault1_lev   \n",
       "586           thibault1_cor   \n",
       "587            thibaud1_son   \n",
       "588            these_pit_09   \n",
       "\n",
       "                                                  tags  is_same  \n",
       "0    {Sync, Trans, Speaker, Turn, Section, Comment,...     True  \n",
       "1    {Sync, Trans, Speaker, Turn, Section, Comment,...     True  \n",
       "2    {Sync, Trans, Speaker, Turn, Section, Comment,...     True  \n",
       "3    {Sync, Trans, Speaker, Turn, Section, Episode,...     True  \n",
       "4    {Sync, Trans, Speaker, Turn, Section, Comment,...     True  \n",
       "..                                                 ...      ...  \n",
       "584  {Sync, Topics, Trans, Speaker, Topic, Turn, Se...     True  \n",
       "585  {Sync, Topics, Trans, Speaker, Topic, Turn, Se...     True  \n",
       "586  {Sync, Topics, Trans, Speaker, Topic, Turn, Se...     True  \n",
       "587  {Sync, Topics, Trans, Speaker, Topic, Turn, Se...     True  \n",
       "588  {Sync, Topics, Trans, Speaker, Topic, Turn, Se...     True  \n",
       "\n",
       "[589 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnrtl_tagstrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcd116",
   "metadata": {},
   "source": [
    "Tous les fichiers trs ont les mêmes tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4fd06",
   "metadata": {},
   "source": [
    "# Parsage fichier .trs \n",
    "\n",
    "1. extrait toutes les données du fichier .trs (possible de récupérer également des données qui n'apparaissent pas dans le dataframe final, comme le topic)\n",
    "2. Output un dataframe pour chaque fichier .trs avec à chaque ligne un tour de parole, son début, sa fin, le locuteur et ses caractéristiques, le fichier audio, l'encoding et *le texte synchronisé*\n",
    "\n",
    "*NB : le texte synchronisé n'est pas encore optimal, j'ai du mal à récupérer le texte entre deux balises Sync, car d'autres balises Event sont aussi utilisées + l'encodage est tjrs en iso*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "689dc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding2(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding'] \n",
    "    # Open the file with the detected encoding\n",
    "    with open(file, 'r', encoding=encoding) as f:\n",
    "        soup = BeautifulSoup(f, \"lxml-xml\")\n",
    "    return soup, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "88df5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trs2(file):\n",
    "    transcription = [\"nom_fichier\", \"transcripteur\",\"reviseur\",\"format\", \"nombre_mots\", \"convention_transcription\"]\n",
    "    referencement = [\"nom_corpus\", \"responsable\", \"titre\", \"laboratoire\"]\n",
    "    locuteur_tag = ['age','sexe','etude','formation','profession_actuelle','profession_anterieure','role','degre','statut_francais','autre_langue','relation_locuteur','naissance','residence','appartenance','particularite','nombre_mots','temps_parole']\n",
    "    soup, encoding = detect_encoding2(file)\n",
    "    my_dict = {}\n",
    "    dict_trans, audio_filename = get_trans2(soup, my_dict)\n",
    "    my_dict.update(dict_trans)  \n",
    "    dict_loc = get_speaker2(soup, my_dict)\n",
    "    my_dict.update(dict_loc)\n",
    "    my_dict.update(get_topics2(soup, my_dict))\n",
    "    my_dict.update(get_section2(soup, my_dict))\n",
    "    dict_turns = get_turn2(soup)\n",
    "    df = pd.DataFrame.from_dict(dict_turns,orient='index')\n",
    "    df['audio_filename']= audio_filename\n",
    "    df['encoding']=encoding\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "cac80603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans2(soup, my_dict):\n",
    "    trans = soup.find('Trans')\n",
    "    # create a dictionary of locuteurs\n",
    "    if trans is not None:\n",
    "        audio_filename = trans.get('audio_filename')\n",
    "        my_dict['audio_filename'] = audio_filename\n",
    "    return my_dict, audio_filename\n",
    "\n",
    "def get_speaker2(soup, my_dict):\n",
    "    speakers = soup.find_all('Speaker')\n",
    "    # create a dictionary of speakers\n",
    "    for speaker in speakers:\n",
    "        scope = speaker.get('scope')\n",
    "        accent = speaker.get('accent')\n",
    "        dialect = speaker.get('dialect')\n",
    "        check = speaker.get('check')\n",
    "        name = speaker.get('name')\n",
    "        id_ = speaker.get('id')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_locuteur = {}\n",
    "        dict_locuteur['scope'] = scope\n",
    "        dict_locuteur['accent'] = accent\n",
    "        dict_locuteur['dialect'] = dialect\n",
    "        dict_locuteur['check'] = check\n",
    "        dict_locuteur['name'] = name\n",
    "        dict_locuteur['id'] = id_\n",
    "        my_dict[id_] = dict_locuteur\n",
    "    return my_dict\n",
    "\n",
    "def get_topics2(soup, my_dict):\n",
    "    topics = soup.find_all('Topic')\n",
    "    # create a dictionary of locuteurs\n",
    "    for topic in topics:\n",
    "        id_ = topic.get('id')\n",
    "        desc = topic.get('desc')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_topic = {}\n",
    "        dict_topic['desc'] = desc\n",
    "        dict_topic['id'] = id_\n",
    "        my_dict[id_] = dict_topic\n",
    "    return my_dict\n",
    "\n",
    "def get_section2(soup, my_dict):\n",
    "    sections = soup.find_all('Section')\n",
    "    # create a dictionary of locuteurs\n",
    "    for section in sections:\n",
    "        topic = section.get('topic')\n",
    "        endTime = section.get('endTime')\n",
    "        startTime = section.get('startTime')\n",
    "        type_ = section.get('type')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_section = {}\n",
    "        dict_section['topic'] = topic\n",
    "        dict_section['endTime'] = endTime\n",
    "        dict_section['startTime'] = startTime\n",
    "        dict_section['type'] = type_\n",
    "        my_dict['section_{}'.format(topic)] = dict_section\n",
    "    return my_dict\n",
    "\n",
    "def get_turn2(soup):\n",
    "    turns = soup.find_all('Turn')\n",
    "    dict_turns = {}\n",
    "    dict_loc = {}\n",
    "    dict_loc.update(get_speaker2(soup, dict_loc))\n",
    "    for index, turn in enumerate(turns):\n",
    "        endTime = turn.get('endTime')\n",
    "        startTime = turn.get('startTime')\n",
    "        speaker = turn.get('speaker')\n",
    "        sync_tags = turn.find_all('Sync')\n",
    "        result = get_sync_times(turn)\n",
    "        text = turn.text.encode('iso-8859-1').decode('utf-8')\n",
    "        dict_turn = {}\n",
    "        dict_turn['startTime']=startTime\n",
    "        dict_turn['endTime']=endTime\n",
    "        dict_turn['speaker'] = speaker\n",
    "        dict_turn['speaker_characteristic'] = dict_loc.get('{}'.format(speaker))\n",
    "        dict_turn['text']= text.replace('\\n','')\n",
    "        dict_turn['text_synchronisé'] = result\n",
    "        dict_turns['{}'.format(index)] = dict_turn\n",
    "    return dict_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "70de23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sync_times(turn):\n",
    "    sync_tags = turn.find_all('Sync')\n",
    "    sync_times = [float(sync_tag['time']) for sync_tag in sync_tags]\n",
    "    text = turn.get_text().replace('\\n\\n','\\n').strip().splitlines()\n",
    "    result = [(sync_time, text) for sync_time, text in list(zip(sync_times, text))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "85b08243",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_turn = [parse_trs2(file) for file in trs_files_cnrtl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ab590f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_characteristic</th>\n",
       "      <th>text</th>\n",
       "      <th>text_synchronisé</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>spk1</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>et au niveau des tenues pour le sport il y en ...</td>\n",
       "      <td>[(0.0, et au niveau des tenues pour le sport i...</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.73</td>\n",
       "      <td>47.069</td>\n",
       "      <td>spk2</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>euh alors euh déjà j'ai jamais compris pourquo...</td>\n",
       "      <td>[(3.73, euh alors euh dÃ©jÃ  j'ai jamais compr...</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.069</td>\n",
       "      <td>54.832</td>\n",
       "      <td>spk1</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>mais euh comment je veux te dire à porter enfi...</td>\n",
       "      <td>[(47.069, mais euh comment je veux te dire Ã  ...</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.832</td>\n",
       "      <td>56.053</td>\n",
       "      <td>spk2</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>euh</td>\n",
       "      <td>[(54.832, euh)]</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.053</td>\n",
       "      <td>58.788</td>\n",
       "      <td>spk1</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>porter un kimono ou euh quand tu fais du sport</td>\n",
       "      <td>[(56.053, porter un kimono ou euh quand tu fai...</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>594.411</td>\n",
       "      <td>596.56</td>\n",
       "      <td>spk1</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>mais euh les &lt; les Italiens avec</td>\n",
       "      <td>[(594.411, mais euh les &lt; les Italiens avec)]</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>596.56</td>\n",
       "      <td>603.169</td>\n",
       "      <td>spk2</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>les plongeons &gt; toutes les deux secondes à pei...</td>\n",
       "      <td>[(596.56, les plongeons &gt; toutes les deux seco...</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>603.169</td>\n",
       "      <td>605.272</td>\n",
       "      <td>spk1</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>même le Brésilien Ronaldo hein</td>\n",
       "      <td>[(603.169, mÃªme le BrÃ©silien Ronaldo hein)]</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>605.272</td>\n",
       "      <td>605.873</td>\n",
       "      <td>spk2</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>oui</td>\n",
       "      <td>[(605.272, oui)]</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>605.873</td>\n",
       "      <td>630.155</td>\n",
       "      <td>spk1</td>\n",
       "      <td>{'scope': 'local', 'accent': '', 'dialect': 'n...</td>\n",
       "      <td>c'est lui euh c'est un il le reconnait après l...</td>\n",
       "      <td>[(605.873, c'est lui euh c'est un il le reconn...</td>\n",
       "      <td>sports_pet_07.wav</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    startTime  endTime speaker  \\\n",
       "0           0     3.73    spk1   \n",
       "1        3.73   47.069    spk2   \n",
       "2      47.069   54.832    spk1   \n",
       "3      54.832   56.053    spk2   \n",
       "4      56.053   58.788    spk1   \n",
       "..        ...      ...     ...   \n",
       "120   594.411   596.56    spk1   \n",
       "121    596.56  603.169    spk2   \n",
       "122   603.169  605.272    spk1   \n",
       "123   605.272  605.873    spk2   \n",
       "124   605.873  630.155    spk1   \n",
       "\n",
       "                                speaker_characteristic  \\\n",
       "0    {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "1    {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "2    {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "3    {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "4    {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "..                                                 ...   \n",
       "120  {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "121  {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "122  {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "123  {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "124  {'scope': 'local', 'accent': '', 'dialect': 'n...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    et au niveau des tenues pour le sport il y en ...   \n",
       "1    euh alors euh déjà j'ai jamais compris pourquo...   \n",
       "2    mais euh comment je veux te dire à porter enfi...   \n",
       "3                                                 euh    \n",
       "4       porter un kimono ou euh quand tu fais du sport   \n",
       "..                                                 ...   \n",
       "120                   mais euh les < les Italiens avec   \n",
       "121  les plongeons > toutes les deux secondes à pei...   \n",
       "122                    même le Brésilien Ronaldo hein    \n",
       "123                                                oui   \n",
       "124  c'est lui euh c'est un il le reconnait après l...   \n",
       "\n",
       "                                      text_synchronisé     audio_filename  \\\n",
       "0    [(0.0, et au niveau des tenues pour le sport i...  sports_pet_07.wav   \n",
       "1    [(3.73, euh alors euh dÃ©jÃ  j'ai jamais compr...  sports_pet_07.wav   \n",
       "2    [(47.069, mais euh comment je veux te dire Ã  ...  sports_pet_07.wav   \n",
       "3                                      [(54.832, euh)]  sports_pet_07.wav   \n",
       "4    [(56.053, porter un kimono ou euh quand tu fai...  sports_pet_07.wav   \n",
       "..                                                 ...                ...   \n",
       "120      [(594.411, mais euh les < les Italiens avec)]  sports_pet_07.wav   \n",
       "121  [(596.56, les plongeons > toutes les deux seco...  sports_pet_07.wav   \n",
       "122      [(603.169, mÃªme le BrÃ©silien Ronaldo hein)]  sports_pet_07.wav   \n",
       "123                                   [(605.272, oui)]  sports_pet_07.wav   \n",
       "124  [(605.873, c'est lui euh c'est un il le reconn...  sports_pet_07.wav   \n",
       "\n",
       "       encoding  \n",
       "0    ISO-8859-1  \n",
       "1    ISO-8859-1  \n",
       "2    ISO-8859-1  \n",
       "3    ISO-8859-1  \n",
       "4    ISO-8859-1  \n",
       "..          ...  \n",
       "120  ISO-8859-1  \n",
       "121  ISO-8859-1  \n",
       "122  ISO-8859-1  \n",
       "123  ISO-8859-1  \n",
       "124  ISO-8859-1  \n",
       "\n",
       "[125 rows x 8 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df_turn[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab844c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

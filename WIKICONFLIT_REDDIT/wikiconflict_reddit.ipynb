{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e01357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_tei(file_path):\n",
    "    print(file_path)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'xml')\n",
    "    \n",
    "    posts = soup.find_all('post')\n",
    "    results = []\n",
    "    for post in posts:\n",
    "        xml_id = post['xml:id']\n",
    "        try : \n",
    "            n = post['n']\n",
    "        except:\n",
    "            n = ''\n",
    "        who = post['who']\n",
    "        date_attr = [attr for attr in post.attrs if re.match(r'when.*', attr)]\n",
    "        if date_attr:\n",
    "            date = post[date_attr[0]]\n",
    "        else:\n",
    "            date = None\n",
    "        texte = ' '.join([x.get_text() for x in post.find_all('p')])\n",
    "        texte_mod =re.sub(\"\\\\\\'\", \"\\'\", texte)\n",
    "        texte = re.sub(r'\\n\\s+', ' ', texte_mod)\n",
    "        sujet = file_path.replace('F:\\Corpus\\wikiconflict\\cmr-wikiconflits-','').replace('_discu-tei-v1.xml','')\n",
    "        results.append({'xml_id': xml_id, 'date': date, 'n':n, 'who':who, 'texte':texte, 'sujet':sujet})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7de70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_directory(directory):\n",
    "    file_list = []\n",
    "    # Vérifier si le dossier existe\n",
    "    if os.path.exists(directory):\n",
    "        # Parcourir tous les fichiers du dossier\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_list.append(file_path)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_dataframe(dictionary):\n",
    "    df = pd.DataFrame(dictionary)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6014d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_files_in_directory('F:\\Corpus\\wikiconflict')\n",
    "posts = [parse_xml_tei(file_path) for file_path in path]\n",
    "\n",
    "all_ = pd.concat([dict_to_dataframe(x) for x in posts])\n",
    "all_.to_csv('F:\\Corpus\\\\finaux\\wikiconflict.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple \n",
    "file_path = 'F:\\Corpus\\wikiconflict\\cmr-wikiconflits-bogdanoff_discu-tei-v1.xml'\n",
    "posts = parse_xml_tei(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a835a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = pd.concat([dict_to_dataframe(x) for x in posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba648fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_reddit_xml(file_path):\n",
    "    #tree = ET.parse(file_path, parser = ET.XMLParser(encoding = 'utf-8'))\n",
    "    root =  ET.fromstring(file_path)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for s in root.findall('s'):\n",
    "        link_id = s.get('link_id')\n",
    "        subreddit_id = s.get('subreddit_id')\n",
    "        \n",
    "        for utt in s.findall('utt'):\n",
    "            uid = utt.get('uid')\n",
    "            comment_id = utt.get('comment_id')\n",
    "            parent_id = utt.get('parent_id')\n",
    "            score = utt.get('score')\n",
    "            create_utc = utt.get('create_utc')\n",
    "            text = utt.text.strip()\n",
    "            \n",
    "            data.append({\n",
    "                'link_id': link_id,\n",
    "                'subreddit_id': subreddit_id,\n",
    "                'uid': uid,\n",
    "                'comment_id': comment_id,\n",
    "                'parent_id': parent_id,\n",
    "                'score': score,\n",
    "                'create_utc': create_utc,\n",
    "                'text': text\n",
    "            })\n",
    "    time.sleep(3)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_control_characters(xml_file):\n",
    "    with open(xml_file, 'r', encoding='utf-8') as file:\n",
    "        xml_content = file.read()\n",
    "\n",
    "    # Supprimer les caractères de contrôle\n",
    "    cleaned_content = re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]', '', xml_content)\n",
    "\n",
    "    return cleaned_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "    # Supprimer les sauts de ligne en trop\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    \n",
    "    # Supprimer les espaces en trop\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    # Supprimer les caractères d'échappement '\\' suivis de \"'\"\n",
    "    text = re.sub(r'\\\\\\'', \"'\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f21fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_in_dict_list(dict_list):\n",
    "    cleaned_list = [\n",
    "        {key: clean_string(value) if key == 'text' else value for key, value in data.items()}\n",
    "        for data in dict_list\n",
    "    ]\n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = remove_control_characters(r\"F:\\Corpus\\reddit\\archive\\final_SPF_2.xml\")\n",
    "\n",
    "d = parse_reddit_xml(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_list = clean_text_in_dict_list(d)\n",
    "\n",
    "df = pd.DataFrame(cleaned_data_list)\n",
    "\n",
    "df.to_csv(r'F:\\Corpus\\finaux\\reddit.csv', sep ='\\t', encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc243b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver #Webdriver de Selenium qui permet de contrôler un navigateur\n",
    "from selenium.webdriver.common.by import By #Permet d'accéder aux différents élements de la page web\n",
    "from webdriver_manager.chrome import ChromeDriverManager #Assure la gestion du webdriver de Chrome\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9034e",
   "metadata": {},
   "source": [
    "SELENIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument(\"--window-size=1920,1200\")\n",
    "options.add_argument(\"--download.default_directory=E:\\\\Corpus\\\\CLAPI_scrape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install(),options=options)  #Initialisation du driver\n",
    "driver.implicitly_wait(0.5)\n",
    "time.sleep(3) #Ajout d'un temps de deux secondes avant de lancer l'action suivante\n",
    "driver.get(\"http://clapi.icar.cnrs.fr/V3_Feuilleter.php?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453659cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_corpus(driver):\n",
    "    corpus_suivant = driver.find_element(By.XPATH, \"//input[@value='Corpus suivant']\")\n",
    "    corpus_suivant.click()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147dc4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_name(driver):\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source,features='html.parser')\n",
    "    pattern = r'Corpus [0-9]+ sur 69 : (.*)' # Define the pattern using a regular expression\n",
    "    tag = soup.find(text=re.compile(pattern)) # Find the tag that contains the pattern\n",
    "    match = re.search(pattern, tag) # Extract the matching text using the regular expression pattern\n",
    "    corpus_name = match.group(1) # Extract the text group and save it in the corpus_name variable\n",
    "    return corpus_name # Print the corpus_name variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_corpus(page_html, driver):\n",
    "    soup = BeautifulSoup(page_html,features='html.parser')\n",
    "    pattern = r'Corpus [0-9]+ sur 69 : (.*)' \n",
    "    tag = soup.find(text=re.compile(pattern))\n",
    "    match = re.search(pattern, tag) \n",
    "    corpus_name = match.group(1) \n",
    "    metadata_corpus = soup.find('div', {'id':'u262container'})\n",
    "    autrice_corpus = metadata_corpus.find('div', {'id':'u274_rtf'}).get_text()\n",
    "    date_collecte_corpus = metadata_corpus.find('div', {'id':'u276_rtf'}).get_text()\n",
    "    duree_corpus = metadata_corpus.find('div', {'id':'u280_rtf'}).get_text()\n",
    "    langue_corpus = metadata_corpus.find('div', {'id':'u282_rtf'}).get_text()\n",
    "    print('Corpus_name : ', corpus_name)\n",
    "    print('\\n')\n",
    "    print('auteur.rice : ', autrice_corpus)\n",
    "    print('date_collecte_corpus : ', date_collecte_corpus)\n",
    "    print('duree_corpus : ', duree_corpus)\n",
    "    print('langue_corpus : ', langue_corpus)\n",
    "    nb_enregistrement, liste_df = enregistrement(soup, driver)\n",
    "    print('nb_enregistrement: ', nb_enregistrement)\n",
    "    for df in liste_df:\n",
    "        df['nom_corpus'] = corpus_name\n",
    "        df['responsable'] = autrice_corpus\n",
    "        df['duree_corpus'] = duree_corpus\n",
    "        df['langue_corpus'] = langue_corpus\n",
    "    print('___________________________________')\n",
    "    return liste_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(liste):\n",
    "    if not liste:\n",
    "        liste = ''\n",
    "    elif len(liste)>1:\n",
    "        liste = liste[-1].get_text()\n",
    "    elif len(liste) == 1:\n",
    "        liste = liste[0].get_text()\n",
    "    else : \n",
    "        liste = ''    \n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fcf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enregistrement(soup, driver):\n",
    "    nb_enregistrements = int(soup.find('div', {'id':'u286_rtf'}).get_text().replace(' Enregistrements ', '').replace(' Enregistrement ', ''))\n",
    "    liste_enregistrement = soup.find_all('div', {'id':'ou344'})\n",
    "    liste_df = []\n",
    "    for i in range(nb_enregistrements):\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source,features='html.parser')\n",
    "        nom_enregistrement = soup.find('div', {'id':'u524_rtf'}).get_text()\n",
    "    \n",
    "        description = soup.find_all('div', {'id':'u380'})\n",
    "        description = get_element(description)\n",
    "        \n",
    "        data_collecte = soup.find_all('div', {'id':'u372_rtf'})\n",
    "        data_collecte = get_element(data_collecte)\n",
    "\n",
    "        duree = soup.find_all('div', {'id':'u374_rtf'})\n",
    "        duree = get_element(duree)\n",
    "\n",
    "        nb_locuteurs = soup.find_all('div', {'id':'u376_rtf'})\n",
    "        nb_locuteurs = get_element(nb_locuteurs)\n",
    "        \n",
    "        langue_lieu = soup.find_all('div', {'id':'u378_rtf'})\n",
    "        langue_lieu = get_element(langue_lieu)\n",
    "\n",
    "        table_locuteur = soup.find_all('div', {'id':'u392container'})[-1]\n",
    "        noms_locuteurs = [x.get_text() for x in table_locuteur.find_all('div', {'id':'u404_rtf'})]\n",
    "        sexe_locuteurs = [x.get_text() for x in table_locuteur.find_all('div', {'id':'u406_rtf'})]\n",
    "        age_locuteurs = [x.get_text() for x in table_locuteur.find_all('div', {'id':'u408_rtf'})]\n",
    "        langue_locuteurs = [x.get_text() for x in table_locuteur.find_all('div', {'id':'u410_rtf'})]\n",
    "        profession_locuteurs = [x.get_text() for x in table_locuteur.find_all('div', {'id':'u412_rtf'})]\n",
    "        print('\\n')\n",
    "        print('ENREGISTREMENT {}'.format(i+1))\n",
    "        print('nom_enregistrement : ', nom_enregistrement)\n",
    "        print('description : ', description)\n",
    "        print('data_collecte : ', data_collecte)\n",
    "        print('duree : ', duree)\n",
    "        print('nb_locuteurs : ', nb_locuteurs)\n",
    "        print('langue_lieu : ', langue_lieu)\n",
    "        print('noms_locuteurs : ', noms_locuteurs)\n",
    "        print('sexe_locuteurs : ', sexe_locuteurs)\n",
    "        print('age_locuteurs : ', age_locuteurs)\n",
    "        print('langue_locuteurs : ', langue_locuteurs)\n",
    "        print('profession_locuteurs : ', profession_locuteurs)\n",
    "        dict_loc = {}\n",
    "        for index in range(len(noms_locuteurs)):\n",
    "            dict_loc[index] = {\n",
    "        'nom': noms_locuteurs[index],\n",
    "        'sexe': sexe_locuteurs[index],\n",
    "        'age': age_locuteurs[index],\n",
    "        'profession': profession_locuteurs[index],\n",
    "        'langue': langue_locuteurs[index]}\n",
    "\n",
    "        # Find the element using its XPath\n",
    "        element = driver.find_element(By.XPATH, xpath_soup(liste_enregistrement[i]))\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        time.sleep(2)\n",
    "\n",
    "        df = pd.DataFrame({'nom_enregistrement': nom_enregistrement,\n",
    "            'description': description,\n",
    "            'date_collecte': data_collecte,\n",
    "            'duree': duree,\n",
    "            'nb_locuteurs': nb_locuteurs,\n",
    "            'langue_lieu': langue_lieu,\n",
    "            'locuteurs': str(dict_loc) }, index=[0])\n",
    "\n",
    "        liste_df.append(df)\n",
    "    return nb_enregistrements, liste_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xpath_soup(element):\n",
    "    components = []\n",
    "    child = element if element.name else element.parent\n",
    "    for parent in child.parents:\n",
    "        siblings = parent.find_all(child.name, recursive=False)\n",
    "        components.append(\n",
    "            child.name\n",
    "            if siblings == [child] else\n",
    "            '%s[%d]' % (child.name, 1 + siblings.index(child))\n",
    "            )\n",
    "        child = parent\n",
    "    components.reverse()\n",
    "    return '/%s' % '/'.join(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d91381",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_data_clapi = []\n",
    "nom_ancien = ''\n",
    "while nom_ancien != get_corpus_name(driver):\n",
    "    print('nom ancien: ', nom_ancien)\n",
    "    print('nom actuel: ', get_corpus_name(driver))\n",
    "    liste_df = get_metadata_corpus(driver.page_source, driver)\n",
    "    liste_data_clapi.append(liste_df)\n",
    "    time.sleep(1)\n",
    "    nom_ancien = get_corpus_name(driver)\n",
    "    time.sleep(1)\n",
    "    next_corpus(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e97aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= liste_data_clapi[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "from bs4.element import NavigableString, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_folder(path):\n",
    "    directory = os.listdir(path)\n",
    "    folder_list = []\n",
    "    for folder in directory:\n",
    "        if os.path.isdir(os.path.join(path, folder)):\n",
    "            folder_list.append('{}{}/'.format(path, folder))\n",
    "        else:\n",
    "            folder_list.append(path)\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb29674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(path):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            extension = os.path.splitext(file_path)[1]\n",
    "            file_list.append((file_path, extension))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(liste):\n",
    "    flattened_list = []\n",
    "    for sublist in liste:\n",
    "        for item in sublist:\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd3004",
   "metadata": {},
   "source": [
    "# extract all corpus folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe87140",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dossier = get_all_folder(\"E:/Corpus/clapi/clapi/2/CorpusComplet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb347edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_corpus = [get_all_folder(x) for x in liste_dossier]\n",
    "liste_corpus = list(set(flatten_list(liste_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in liste_corpus:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac192d2a",
   "metadata": {},
   "source": [
    "# Create dataframe to store all files inside a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_key(dict_corpus, extension):\n",
    "    if extension not in dict_corpus:\n",
    "        key = '{}'.format(extension)\n",
    "    else: \n",
    "        for i in range(1,100):\n",
    "            possible_name =  '{}{}'.format(extension, i)\n",
    "            if possible_name not in dict_corpus:\n",
    "                key = possible_name\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73093d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for x in liste_corpus:  \n",
    "    dict_corpus = {}\n",
    "    pattern = r'[\\S]+\\/([\\S]+)\\/'\n",
    "    match = re.search(pattern, x) \n",
    "    dict_corpus['corpus_name'] = str(match.group(1))\n",
    "    for file, extension in get_all_files(x):\n",
    "        if extension=='.xml':\n",
    "            if file.endswith('OLAC.xml'):\n",
    "                dict_corpus['olac']=file\n",
    "            elif file.endswith('TEI.xml'):\n",
    "                dict_corpus['tei']=file\n",
    "            else:\n",
    "                dict_corpus['{}'.format(create_new_key(dict_corpus, extension))]=file\n",
    "        else: \n",
    "            dict_corpus['{}'.format(create_new_key(dict_corpus, extension))]=file\n",
    "    df = df.append([dict_corpus], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcc1d1",
   "metadata": {},
   "source": [
    "# Inspect xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076efdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding'] \n",
    "    # Open the file with the detected encoding\n",
    "    with open(file, 'r', encoding=encoding) as f:\n",
    "        soup = BeautifulSoup(f, \"lxml-xml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tagsname(xml_file):\n",
    "    # Parse the XML file into an ElementTree object\n",
    "    try : \n",
    "        tree = ET.parse(xml_file)\n",
    "    # Get the root element of the tree\n",
    "        root = tree.getroot()\n",
    "    # Initialize an empty set to store the tag names\n",
    "        tag_names = set()\n",
    "    # Iterate over all elements in the tree and add their tag names to the set\n",
    "        for elem in root.iter():\n",
    "            tag_names.add(elem.tag)\n",
    "    # Return the set of tag names\n",
    "    except: \n",
    "        return \"Pas de fichier trouvé à cet emplacement\"\n",
    "    return tag_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tags = []\n",
    "for index, xml in enumerate(df['tei'].tolist()): \n",
    "    tags = []\n",
    "    try : \n",
    "        soup = detect_encoding(xml)\n",
    "        try : \n",
    "            tags_file = list(get_all_tagsname(xml))\n",
    "            try :  \n",
    "                tag = []\n",
    "                for x in tags_file : \n",
    "                    pattern = r'\\{[\\S]+\\}([\\S]+)'\n",
    "                    match = re.search(pattern, x) \n",
    "                    tag.append(match.group(1))\n",
    "                tags.append(tag)\n",
    "            except: \n",
    "                for x in tags_file : \n",
    "                    tags.append(x.replace('{http://purl.org/dc/elements/1.1/}','').replace('{http://purl.org/dc/terms/}',''))\n",
    "        except: \n",
    "            tags.append('')\n",
    "    except : \n",
    "        tags.append('')\n",
    "    list_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tei_tags'] = list_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01984114",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tags_olac = []\n",
    "for index, xml in enumerate(df['olac'].tolist()): \n",
    "    tags = []\n",
    "    try : \n",
    "        soup = detect_encoding(xml)\n",
    "        try : \n",
    "            tags_file = list(get_all_tagsname(xml))\n",
    "            try :  \n",
    "                tag = []\n",
    "                for x in tags_file : \n",
    "                    pattern = r'\\{[\\S]+\\}([\\S]+)'\n",
    "                    match = re.search(pattern, x) \n",
    "                    tag.append(match.group(1))\n",
    "                tags.append(tag)\n",
    "            except: \n",
    "                for x in tags_file : \n",
    "                    tags.append(x.replace('{http://purl.org/dc/elements/1.1/}','').replace('{http://purl.org/dc/terms/}',''))\n",
    "        except: \n",
    "            tags.append('')\n",
    "    except : \n",
    "        tags.append('')\n",
    "    list_tags_olac.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['olac_tags'] = list_tags_olac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(liste):\n",
    "    flattened_list = []\n",
    "    for sublist in liste:\n",
    "        for item in sublist:\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(list1, list2):\n",
    "    s = set(list1)\n",
    "    difference = [x for x in list2 if x not in s]\n",
    "    if difference : \n",
    "        return difference\n",
    "    else: \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(df, col):\n",
    "    # prendre la liste des tags + l'intersection de toutes les listes\n",
    "    lists_tags = df['{}'.format(col)].tolist()\n",
    "    results_union = set().union(*lists_tags)\n",
    "    # trouver les différences entre l'intersection de toutes les listes et la liste des tags d'un corpus donné\n",
    "    df['is_same{}'.format(col)] = df['{}'.format(col)].apply(lambda x:is_same(x, results_union))\n",
    "    return results_union, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_union_olac, df = get_difference(df,'olac_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea670ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tei_tags'] = df['tei_tags'].apply(lambda x : flatten_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_union_tei, df = get_difference(df,'tei_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b02cb",
   "metadata": {},
   "source": [
    "## Liste des tags communs dans les fichiers TEI. xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_union_tei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328fc7e",
   "metadata": {},
   "source": [
    "## Liste des tags communs dans les fichiers OLAC. xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9320502",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_union_olac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1526b2c",
   "metadata": {},
   "source": [
    "## DF TRANSCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb51bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcription = df.copy().drop(['.mp3', 'olac', 'tei', '.wav','.mp4','.mp41','.wmv','.mp42','.avi','.mp31','tei_tags','olac_tags','is_sameolac_tags','is_sametei_tags'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d69c19",
   "metadata": {},
   "source": [
    "## Analyse du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcription.isnull().sum() #la MAJORITE des corpus ne sont pas transcrits !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad294af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcription.isnull().sum().sum() #all the missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcription.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa92043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

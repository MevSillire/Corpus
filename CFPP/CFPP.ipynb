{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ce16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import wget\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import chardet\n",
    "from pprint import pprint\n",
    "from bs4.element import NavigableString, Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2394fb0",
   "metadata": {},
   "source": [
    "# depuis internet #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('http://cfpp2000.univ-paris3.fr/Corpus.html')\n",
    "soup = BeautifulSoup(page.content, 'html') # If this line causes an error, run 'pip install html5lib' or install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = soup.find_all('li')\n",
    "\n",
    "enregistrements = [x.get_text() for x in li if re.search(r'\\xa0CFPP2000 .*', x.get_text())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = soup.find_all('li',{'class':'linopucetransc'})\n",
    "urls = ['http://cfpp2000.univ-paris3.fr'+a['href'][1:] for x in trans for a in x.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = soup.find_all('li',{'class':'linopuceaudio'})\n",
    "urls_wav = ['http://cfpp2000.univ-paris3.fr'+a['href'][1:] for x in wav for a in x.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url2file(url):\n",
    "    #try:\n",
    "    path = r'E:/Corpus/CFPP'\n",
    "    wget.download(url,out = path)\n",
    "    print('téléchargé : {}'.format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls_wav:\n",
    "    print(url)\n",
    "    url2file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edae010",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    url2file(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a7316",
   "metadata": {},
   "source": [
    "# get all files #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_folder(path):\n",
    "    directory = os.listdir(path)\n",
    "    folder_list = []\n",
    "    for folder in directory:\n",
    "        if os.path.isdir(os.path.join(path, folder)):\n",
    "            folder_list.append(folder)\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ae637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path2corpus(path,corpus):\n",
    "    new = '{}/{}'.format(path, corpus)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e096ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'F:/Corpus/cfpp2000/cfpp2000/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [add_path2corpus(path,x) for x in get_all_folder(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e37e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enregistrements = [add_path2corpus(x,y) for x in corpus for y in get_all_folder(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_files(path):\n",
    "    files = {}\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.xml'):\n",
    "            files['xml']=file\n",
    "        elif file.endswith('.trs'):\n",
    "                files['trs']=file\n",
    "        elif file.endswith('.wav'):\n",
    "            files['wav']=file\n",
    "        else:\n",
    "            continue\n",
    "    return files\n",
    "\n",
    "def get_files_cfpp(list_corpus_path):\n",
    "    mydict = {}\n",
    "    for corpus_path in list_corpus_path:\n",
    "        dict_corpus = get_corpus_files(corpus_path)\n",
    "        mydict[corpus_path]=dict_corpus\n",
    "    df = pd.DataFrame.from_dict(mydict, orient='index').rename_axis('corpus').reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_files_cfpp(enregistrements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6c262",
   "metadata": {},
   "source": [
    "# parse xml #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tagsname(xml_file):\n",
    "    print(xml_file)\n",
    "    # Parse the XML file into an ElementTree object\n",
    "    #try : \n",
    "    tree = ET.parse(xml_file)\n",
    "# Get the root element of the tree\n",
    "    root = tree.getroot()\n",
    "# Initialize an empty set to store the tag names\n",
    "    tag_names = set()\n",
    "# Iterate over all elements in the tree and add their tag names to the set\n",
    "    for elem in root.iter():\n",
    "        tag_names.add(elem.tag)\n",
    "    # Return the set of tag names\n",
    "#     except: \n",
    "#         return \"Pas de fichier trouvé à cet emplacement\"\n",
    "    return tag_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_name(path):\n",
    "    filename = path.replace('.xml','').replace('E:/Corpus/cfpp2000/cfpp2000/4/','')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_tags(xml_files):\n",
    "    corpus_name = [get_corpus_name(xml_file) for xml_file in xml_files]\n",
    "    tags_ = [get_all_tagsname(xml_file) for xml_file in xml_files]\n",
    "    df = pd.DataFrame(list(zip(corpus_name, tags_)), columns = ['corpus_name','tags'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36965f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = [str(x+'/'+y) for x,y in list(zip(df['corpus'].tolist(),df['xml'].tolist())) if isinstance(y,str)]\n",
    "df_tags = get_df_tags(xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_encoding(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding'] \n",
    "    # Open the file with the detected encoding\n",
    "    with open(file, 'r', encoding=encoding) as f:\n",
    "        soup = BeautifulSoup(f, \"lxml-xml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49450040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(file):\n",
    "    print(file)\n",
    "    soup = detect_encoding(file)\n",
    "    pp = soup.find('element',{'type':'Enregistrement'}).find_all('p')\n",
    "    dicti = {}\n",
    "    for p in pp:\n",
    "        pattern = r'(.*) :(.*)'\n",
    "        match = re.search(pattern, p.get_text())\n",
    "        if match:\n",
    "            nom = match.group(1).lower()\n",
    "            valeur = match.group(2)\n",
    "            dicti['corpus']=file.replace('E:/Corpus/cfpp2000/cfpp2000/4/','').replace('.xml','')\n",
    "            dicti['{}'.format(nom)]=valeur\n",
    "    dicti['locuteur'] = get_locuteurs(soup.find_all('description')[-1])\n",
    "    print('______________________________')\n",
    "    print('______________________________')\n",
    "    return dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27331c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(my_dict):\n",
    "    df_corpus = pd.DataFrame([my_dict])\n",
    "    return df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locuteurs(soup):\n",
    "    enregistrement = soup.find('element',{'type':'Enregistrement'})\n",
    "    next_ = enregistrement.find_next_sibling()\n",
    "    dict_loc = {}\n",
    "    i = 0\n",
    "    while next_ is not None:\n",
    "        pp = next_.find_all('p')\n",
    "        dictii = {}\n",
    "        for ind, p in enumerate(pp):\n",
    "            pattern = r'(.*) :(.*)'\n",
    "            match = re.search(pattern, p.get_text())\n",
    "            if match:\n",
    "                nom = match.group(1).lower()\n",
    "                valeur = match.group(2)\n",
    "                dictii['{}'.format(nom)]=valeur\n",
    "                pattern2 = r'prénom et nom.*'\n",
    "                match2 = re.search(pattern2, nom)\n",
    "                if match2 and valeur:\n",
    "                    nom_loc  = valeur\n",
    "                else:\n",
    "                    nom_loc = str(i)\n",
    "                dict_loc['{}'.format(nom_loc)]=dictii\n",
    "        next_ = next_.find_next_sibling()\n",
    "        i +=1\n",
    "    return dict_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(liste_path, df):\n",
    "    list_df =  []\n",
    "    for xml in liste_path:\n",
    "        dicti = parse_xml(xml)\n",
    "        df_corpus = get_df(dicti)\n",
    "        pattern = r'(.*)/.*$'\n",
    "        match = re.search(pattern, xml)\n",
    "        if match:\n",
    "            folder = match.group(1)\n",
    "            df_corpus['trs']=extract_trs_file_name(folder, df)\n",
    "        else:\n",
    "            df_corpus['trs']='NA'\n",
    "        list_df.append(df_corpus)\n",
    "    df = pd.concat(list_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dfe3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def extract_trs_file_name(folder_path, df):\n",
    "    row = df.loc[df['corpus'] == '{}'.format(folder_path)]\n",
    "    trs = row['trs'].values\n",
    "    return trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = get_info(xml_path, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23294e37",
   "metadata": {},
   "source": [
    "# parse trs #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trs2(file):\n",
    "    soup = detect_encoding(file)\n",
    "    my_dict = {}\n",
    "    dict_trans, audio_filename = get_trans2(soup, my_dict)\n",
    "    my_dict.update(dict_trans)  \n",
    "    dict_loc = get_speaker2(soup)\n",
    "    my_dict.update(dict_loc)\n",
    "    my_dict.update(get_topics2(soup, my_dict))\n",
    "    my_dict.update(get_section2(soup, my_dict))\n",
    "    dict_turns = get_turn2(soup)\n",
    "    print(dict_turns)\n",
    "    df = pd.DataFrame.from_dict(dict_turns,orient='index')\n",
    "    df['audio_filename']= audio_filename\n",
    "    df['trs_filename']=file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans2(soup, my_dict):\n",
    "    trans = soup.find('Trans')\n",
    "    # create a dictionary of locuteurs\n",
    "    if trans is not None:\n",
    "        audio_filename = trans.get('audio_filename')\n",
    "        my_dict['audio_filename'] = audio_filename\n",
    "    return my_dict, audio_filename\n",
    "\n",
    "def get_speaker2(soup):\n",
    "    speakers = soup.find_all('Speaker')\n",
    "    # create a dictionary of speakers\n",
    "    my_dict = {}\n",
    "    for speaker in speakers:\n",
    "        scope = speaker.get('scope')\n",
    "        accent = speaker.get('accent')\n",
    "        dialect = speaker.get('dialect')\n",
    "        check = speaker.get('check')\n",
    "        name = speaker.get('name')\n",
    "        id_ = speaker.get('id')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_locuteur = {}\n",
    "        dict_locuteur['scope'] = scope\n",
    "        dict_locuteur['accent'] = accent\n",
    "        dict_locuteur['dialect'] = dialect\n",
    "        dict_locuteur['check'] = check\n",
    "        dict_locuteur['name'] = fix_encoding(name)\n",
    "        dict_locuteur['id'] = id_\n",
    "        my_dict[id_] = dict_locuteur\n",
    "    return my_dict\n",
    "\n",
    "def get_topics2(soup, my_dict):\n",
    "    topics = soup.find_all('Topic')\n",
    "    # create a dictionary of locuteurs\n",
    "    for topic in topics:\n",
    "        id_ = topic.get('id')\n",
    "        desc = topic.get('desc')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_topic = {}\n",
    "        dict_topic['desc'] = desc\n",
    "        dict_topic['id'] = id_\n",
    "        my_dict[id_] = dict_topic\n",
    "    return my_dict\n",
    "\n",
    "def get_section2(soup, my_dict):\n",
    "    sections = soup.find_all('Section')\n",
    "    # create a dictionary of locuteurs\n",
    "    for section in sections:\n",
    "        topic = section.get('topic')\n",
    "        endTime = section.get('endTime')\n",
    "        startTime = section.get('startTime')\n",
    "        type_ = section.get('type')\n",
    "        # create a new dictionary for this speaker\n",
    "        dict_section = {}\n",
    "        dict_section['topic'] = topic\n",
    "        dict_section['endTime'] = endTime\n",
    "        dict_section['startTime'] = startTime\n",
    "        dict_section['type'] = type_\n",
    "        my_dict['section_{}'.format(topic)] = dict_section\n",
    "    return my_dict\n",
    "\n",
    "def get_turn2(soup):\n",
    "    turns = soup.find_all('Turn')\n",
    "    dict_turns = {}\n",
    "    dict_loc = get_speaker2(soup)\n",
    "    results = []\n",
    "    i = 0\n",
    "    for index, turn in enumerate(turns):\n",
    "        speaker = turn.get('speaker')\n",
    "        if speaker is not None:\n",
    "            speakers_ = r'([a-zA-Z]+([0-9]+|)) ([a-zA-Z]+([0-9]+|)) *([a-zA-Z]*([0-9]*|))'\n",
    "            match = re.search(speakers_, speaker)\n",
    "            if match :\n",
    "                print('MULTI SPEAKER')\n",
    "                print(turn)\n",
    "                spk1 = match.group(1)\n",
    "                spk2 = match.group(3)\n",
    "                liste_speaker = [spk1, spk2]\n",
    "                try:\n",
    "                    spk3 = match.group(3)\n",
    "                    liste_speaker.append(spk3)\n",
    "                except:\n",
    "                    pass\n",
    "                result = get_sync_multiple_loc2(turn, liste_speaker)\n",
    "                for spk,text in result:\n",
    "                    print('spk:', spk, 'text: ', text)\n",
    "                    endTime = turn.get('endTime')\n",
    "                    startTime = turn.get('startTime')\n",
    "                    dict_turn = {}\n",
    "                    dict_turn['startTime']=startTime\n",
    "                    print(type(startTime))\n",
    "                    dict_turn['endTime']=endTime\n",
    "                    dict_turn['speaker'] = spk\n",
    "                    dict_turn['speaker_name'] = dict_loc['{}'.format(spk)]['name']\n",
    "                    dict_turn['speaker_native'] = dict_loc['{}'.format(spk)]['dialect']\n",
    "                    dict_turn['text_synchronisé'] = str(((startTime, fix_encoding(text).replace('\\n',''))))\n",
    "                    dict_turn['text']= fix_encoding(text).replace('\\n','')\n",
    "                    dict_turns['{}'.format(i)] = dict_turn\n",
    "                    print('_________________')\n",
    "                    i+=1\n",
    "\n",
    "                #prendre le texte de speaker 1 et le texte de speaker 2 AVEC **ALERT**\n",
    "                # créer un tour par locuteur avec le même start et end time\n",
    "            else: \n",
    "                print('UN SEUL SPEAKER')\n",
    "                print(turn)\n",
    "                endTime = turn.get('endTime')\n",
    "                startTime = turn.get('startTime')\n",
    "                sync_tags = turn.find_all('Sync')\n",
    "                result = get_sync_times2(turn)\n",
    "                text = ' '.join([content for _, content in result])\n",
    "                dict_turn = {}\n",
    "                dict_turn['startTime']=startTime\n",
    "                dict_turn['endTime']=endTime\n",
    "                dict_turn['speaker'] = speaker\n",
    "                dict_turn['speaker_name'] = dict_loc['{}'.format(speaker)]['name']\n",
    "                dict_turn['speaker_native'] = dict_loc['{}'.format(speaker)]['dialect']\n",
    "                #dict_turn['speaker_characteristic'] = dict_loc.get('{}'.format(speaker))\n",
    "                dict_turn['text']= fix_encoding(text).replace('\\n', ' ').replace('  ', ' ')\n",
    "                dict_turn['text_synchronisé'] = str(result).strip('[]')\n",
    "                dict_turns['{}'.format(i)] = dict_turn\n",
    "                print('spk: ', speaker, 'text : ', fix_encoding(text))\n",
    "                print('___________________')\n",
    "                i+=1\n",
    "        else:\n",
    "            endTime = turn.get('endTime')\n",
    "            startTime = turn.get('startTime')\n",
    "            dict_turn = {}\n",
    "            dict_turn['startTime']=startTime\n",
    "            dict_turn['endTime']=endTime\n",
    "            dict_turn['speaker']= turn.text.replace('\\n','')+'***NO SPEAKER***'\n",
    "            dict_turn['speaker_name']= turn.text.replace('\\n','')+'***NO SPEAKER***'\n",
    "            dict_turns['{}'.format(i)] = dict_turn\n",
    "            print('No spk', 'action : ',turn.text.replace('\\n','')+'***ACTIONS***' )\n",
    "            print('---')\n",
    "            i+=1\n",
    "    return dict_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb434e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding(text):\n",
    "    replacements = {\n",
    "        \"Ã¨\": \"è\", # Add more replacements for other problematic characters here\n",
    "        \"Ã¡\": \"á\",\n",
    "        \"Ã¢\": \"â\",\n",
    "        \"Ã£\": \"ã\",\n",
    "        \"Ã¤\": \"ä\",\n",
    "        \"Ã§\": \"ç\",\n",
    "        \"Ã©\": \"é\",\n",
    "        \"Ãª\": \"ê\",\n",
    "        \"Ã«\": \"ë\",\n",
    "        \"Ã­\": \"í\",\n",
    "        \"Ã¯\": \"ï\",\n",
    "        \"Ã±\": \"ñ\",\n",
    "        \"Ã³\": \"ó\",\n",
    "        \"Ã´\": \"ô\",\n",
    "        \"Ã¶\": \"ö\",\n",
    "        \"Ãº\": \"ú\",\n",
    "        \"Ã¼\": \"ü\",\n",
    "        \"Ã½\": \"ý\",\n",
    "        \"Ã¦\": \"æ\",\n",
    "        \"Ã¸\": \"ø\",\n",
    "        \"ÃŸ\": \"ß\",\n",
    "        \"Ã\" : \"à\",\n",
    "        \"à¹\":'ù',\n",
    "        \"à»\":\"û\",\n",
    "        \"\\xa0\":\"\",\n",
    "        \"Â\": \"\",   # Remove non-breaking space\n",
    "        \"â\": \"-\", # Replace en dash\n",
    "        \"â\": \"--\" # Replace em dash\n",
    "        }\n",
    "\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7508fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sync_times2(turn):\n",
    "    sync_tags = turn.find_all('Sync')\n",
    "    list_sync = []\n",
    "    for i, sync_tag in enumerate(sync_tags):\n",
    "        contenu = []\n",
    "        current_tag = sync_tag.next_sibling\n",
    "        while current_tag is not None and current_tag.name != 'Sync':\n",
    "            if isinstance(current_tag, NavigableString):\n",
    "                current_tag_str = current_tag.get_text().replace('\\n','')\n",
    "                contenu.append(fix_encoding(current_tag_str))\n",
    "            elif current_tag.name == 'Event' and current_tag.get('desc') == 'rire':\n",
    "                next_sync = current_tag.find_next_sibling('Sync')\n",
    "                if next_sync:\n",
    "                    current_tag_str = '*rires*'\n",
    "                    contenu.append(fix_encoding(current_tag_str))\n",
    "            current_tag = current_tag.next_sibling\n",
    "        if contenu:\n",
    "            list_sync.append((sync_tag['time'], ' '.join(contenu)))\n",
    "    return list_sync\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sync_multiple_loc2(turn, list_speaker):\n",
    "    who_tags = turn.find_all('Who')\n",
    "    liste_text = []\n",
    "    for i, who_tag in enumerate(who_tags): \n",
    "        contenu = []\n",
    "        current_tag = who_tag.next_sibling\n",
    "        while current_tag is not None and current_tag.name != 'Who': \n",
    "            if isinstance(current_tag, NavigableString): \n",
    "                current_tag_str = current_tag.get_text()\n",
    "                contenu.append(fix_encoding(current_tag_str))\n",
    "            else : \n",
    "                pass\n",
    "            current_tag = current_tag.next_sibling\n",
    "        liste_text.append(''.join(contenu).replace('\\n',' '))\n",
    "    tour = list(zip(list_speaker, liste_text))\n",
    "    return tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71062c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.reset_index().iloc[5]['trs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4313c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_turn= [parse_trs2(file) for file in df['trs'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57368e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autre(dict_meta, nom, L, tipe):\n",
    "    try : \n",
    "        L = L['speaker_name'].replace('(ENQ)','').replace(' ', '').lower()\n",
    "        for x, y  in dict_meta['locuteur'].items():\n",
    "            x = x.replace(' ', '').lower()\n",
    "            if x == L : \n",
    "                tipe = y['{}'.format(tipe)]\n",
    "                return tipe\n",
    "    except:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa437ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta(df_essai, dict_meta, dict_path):\n",
    "    #try\n",
    "    nom = df_essai['trs_filename'].tolist()[0]\n",
    "    print('nom:', nom, type(nom))\n",
    "    try : \n",
    "        dict_corpus = dict_meta['{}'.format(nom)]\n",
    "        dict_loc = dict_corpus['locuteur']\n",
    "        df_essai['sexe_speaker'] = df_essai.apply(lambda row: get_autre(dict_corpus, nom, row, 'sexe'), axis=1)\n",
    "        df_essai['age_speaker'] = df_essai.apply(lambda row: get_autre(dict_corpus, nom, row, 'age au moment de l’enregistrement'), axis=1)\n",
    "        df_essai['profession_speaker'] = df_essai.apply(lambda row: get_autre(dict_corpus, nom, row, 'activité actuelle'), axis=1)\n",
    "        df_essai['appartenance_speaker'] = df_essai.apply(lambda row: get_autre(dict_corpus, nom, row, \"mobilité géographique\"), axis=1)\n",
    "        df_essai['autre_langue_speaker'] = df_essai.apply(lambda row: get_autre(dict_corpus, nom, row, 'langues parlées par le locuteur'), axis=1)\n",
    "        df_essai['etude_speaker'] = df_essai.apply(lambda row: get_autre(dict_corpus, nom, row, \"dernier diplôme obtenu\"), axis=1)\n",
    "\n",
    "        duree = dict_corpus['durée']\n",
    "        date_enregistrement = dict_corpus['date']\n",
    "        langue_enregistrement = 'français'\n",
    "        lieu_enregistrement = 'FRANCE - Région Parisienne - '+ str(dict_corpus['quartier concerné'])\n",
    "\n",
    "        df_essai['description'] = 'NA'\n",
    "        df_essai['duree'] = duree \n",
    "        df_essai['responsable'] = 'NA'\n",
    "        df_essai['date_enregistrement'] = date_enregistrement \n",
    "        df_essai['langue_enregistrement'] = langue_enregistrement \n",
    "        df_essai['lieu_enregistrement'] = lieu_enregistrement \n",
    "        \n",
    "    except KeyError:\n",
    "        df_essai['sexe_speaker'] = 'NA'\n",
    "        df_essai['age_speaker'] = 'NA'\n",
    "        df_essai['profession_speaker'] = 'NA'\n",
    "        df_essai['appartenance_speaker'] = 'NA'\n",
    "        df_essai['autre_langue_speaker'] = 'NA'\n",
    "        df_essai['etude_speaker'] = 'NA'\n",
    "        df_essai['description'] = 'NA'\n",
    "        df_essai['duree'] = 'NA'\n",
    "        df_essai['responsable'] = 'NA'\n",
    "        df_essai['date_enregistrement'] = 'NA'\n",
    "        df_essai['langue_enregistrement'] = 'NA'\n",
    "        df_essai['lieu_enregistrement'] = 'NA'\n",
    "        \n",
    "\n",
    "    path_trs = str(dict_path['{}'.format(nom)]['corpus'])+'\\\\'+ nom\n",
    "    path_wav = str(dict_path['{}'.format(nom)]['corpus'])\n",
    "\n",
    "    df_essai['path_trs'] = path_trs\n",
    "    df_essai['path_wav'] = df_essai['audio_filename'].apply(lambda x : path_wav +'\\\\'+x )\n",
    "        \n",
    "\n",
    "#         print('erreur dico : ', nom)\n",
    "    #df_essai = df_essai.rename(columns={\"corpus_name\": \"sous_corpus\"})\n",
    "    print('______________________________________')\n",
    "    return df_essai\n",
    "   # except:\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_meta = df_meta.set_index('trs').T.to_dict('dict')\n",
    "dict_path = df.set_index('trs').T.to_dict('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [add_meta(df, dict_meta, dict_path) for df in list_df_turn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path['Leo_Valentin_H_52_15e-v2.trs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tours = pd.concat(final)\n",
    "df_tours['duree'] = df_tours['duree'].apply(lambda x : time2seconds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tours = pd.concat(final)\n",
    "df_tours['duree'] = df_tours['duree'].apply(lambda x : time2seconds(x))\n",
    "df_tours['corpus'] = ['CFPP']*len(df_tours)\n",
    "df_tours = df_tours.drop('audio_filename', axis=1)\n",
    "df_tours = df_tours.fillna('NA')\n",
    "df_tours['encoding']='NA'\n",
    "df_tours['sous_corpus'] = df_tours['trs_filename'].apply(lambda x : x.replace('.trs',''))\n",
    "df_tours = df_tours.drop('trs_filename', axis=1)\n",
    "df_tours['age_speaker'] = df_tours['age_speaker'].apply(lambda x : x.replace('et demi', '').replace('  (née en 1977) ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time2seconds(string):\n",
    "    try : \n",
    "        string = string.replace(' (deux fichiers de 53’58’’ et 34’20)','').replace(' heure ', 'h').replace(' ','')\n",
    "        if \"h\" in string : \n",
    "            pattern2 = r'(\\d+)h(\\d*)'\n",
    "            match2 = re.search(pattern2, string)\n",
    "            if match2 : \n",
    "                liste = [int(match2.group(1)),int(match2.group(2)), 0]\n",
    "        elif \"minutes\" in string:\n",
    "            string = string.replace(\"minutes\", '')\n",
    "            liste = [0,int(string),0]\n",
    "\n",
    "        else :    \n",
    "            pattern = r'([0-9]*)([\\S])([0-9]*)'\n",
    "            match = re.search(pattern, string)\n",
    "            if match : \n",
    "                if len(match.group(3))!=0 :\n",
    "                    liste = [0,int(match.group(1)),int(match.group(3))]\n",
    "                else: \n",
    "                    liste = [0,int(match.group(1)),0]\n",
    "\n",
    "        ftr = [3600,60,1]\n",
    "        seconds = sum([multi*value for multi,value in zip(ftr, liste)])\n",
    "        return seconds\n",
    "    except: \n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tours.to_csv('F:\\Corpus\\\\finaux\\CFPP.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
